[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spetses Introductory Course",
    "section": "",
    "text": "Background:\nThis website contains the R teaching material that can be used (it is not compulsory) during the Simulated Outbreak (SimOb) section of the Introductory Course module of the EPIET (European Programme of Intervention Epidemiology Training), EUPHEM (European Public Health Microbiology) and MediPIET (Mediterranean and Black Sea Programme for Intervention Epidemiology Training) fellowships.\nThe SimOb is an 4-day exercise where fellows are provided a series of injects through which they will follow a 10-steps framework to investigate a specific outbreak. Some of the injects are dedicated to R-exercises that can be proved quite handy during an outbreak investigation. Those injects are maintained in this repository and are stored as different .qmd files, under the root folder:\n\nData_import_cleaning.qmd\nCase_definition.qmd\nLab_and_Descriptive.qmd\nUnivariate.qmd\nStratified.qmd"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "SimOb_RInject09.html",
    "href": "SimOb_RInject09.html",
    "title": "Inject 09: Data import and cleaning",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nImport datasets in R\nApply basic data management techniques to explore and familiarise themselves with the dataset\nApply strategies for data cleaning"
  },
  {
    "objectID": "SimOb_RInject09.html#install-packages-and-load-libraries",
    "href": "SimOb_RInject09.html#install-packages-and-load-libraries",
    "title": "Inject 09: Data import and cleaning",
    "section": "3.1. Install packages and load libraries",
    "text": "3.1. Install packages and load libraries\n\nLoad the R packages you will be using. Update this list of packages as you dig into the code: You may realise you need packages you didn’t think about at the beginning. Remember that it is a good practice to load tydiverse at the end of your package list, to avoid masking functions.\n\n\n\nCode\n# Check if the 'pacman' package is installed, if not install it:\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "SimOb_RInject09.html#import-your-data",
    "href": "SimOb_RInject09.html#import-your-data",
    "title": "Inject 09: Data import and cleaning",
    "section": "3.2. Import your data",
    "text": "3.2. Import your data\n\nYou can find the spetses_school.csv file in EVA. Feel free to explore the codebook as well.\n\n\n\nCode\n# Import the raw data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"spetses_school.csv\"))"
  },
  {
    "objectID": "SimOb_RInject09.html#explore-and-clean-your-data",
    "href": "SimOb_RInject09.html#explore-and-clean-your-data",
    "title": "Inject 09: Data import and cleaning",
    "section": "3.3. Explore and clean your data",
    "text": "3.3. Explore and clean your data\n\nHave a look at the structure of your data. Here you have some questions that may help you get started:\n\nHow many observations and variables does the dataset contain?\nWhat types of variables do you have and what types of values are recorded?\nDo any of the values of the other variables look implausible? Which ones and why? What will you do about it?\n\nGo ahead and clean your data as you see fit.\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nYou could use head(), dim(), str(), or skim() to have a quick look at the data and get an idea of which variables you want to explore further. You can also do some tables\n\n\n\n\n\nCode\nhead(copdata)\n\n\n\n\n  \n\n\n\nCode\ndim(copdata)\n\n\n[1] 397  40\n\n\nCode\nstr(copdata)\n\n\n'data.frame':   397 obs. of  40 variables:\n $ id        : chr  \"sp-2-001\" \"sp-3-003\" \"sp-1-005\" \"sp-2-006\" ...\n $ sex       : chr  \"male\" \"female\" \"female\" \"male\" ...\n $ age       : int  18 18 17 17 18 180 16 15 43 16 ...\n $ group     : int  1 1 1 1 1 1 0 1 0 1 ...\n $ class     : int  2 3 1 2 3 2 NA 1 NA 1 ...\n $ diarrhoea : int  1 NA NA NA 1 1 NA 0 1 NA ...\n $ bloody    : int  0 NA NA NA 0 0 NA 0 NA NA ...\n $ vomiting  : int  0 NA NA NA 0 0 NA 0 NA NA ...\n $ abdo      : int  1 NA 1 NA 1 1 NA 0 NA NA ...\n $ nausea    : int  0 NA 1 NA 1 0 NA 1 1 NA ...\n $ fever     : int  NA NA NA NA 0 0 NA 0 NA NA ...\n $ headache  : int  0 NA 1 NA 1 0 NA 1 1 NA ...\n $ jointpain : int  0 NA NA NA 0 0 NA 0 1 NA ...\n $ starthour : int  9 NA NA NA 15 15 NA NA 3 NA ...\n $ meal      : int  1 1 1 0 1 1 1 1 1 1 ...\n $ feta      : int  1 0 NA 0 1 1 1 1 1 1 ...\n $ fetaD     : int  2 0 NA 0 2 2 2 1 2 2 ...\n $ sardines  : int  1 0 NA 0 1 1 1 0 1 1 ...\n $ sardinesD : int  2 0 NA 0 2 2 2 0 2 2 ...\n $ eggplant  : int  0 0 NA 0 1 1 1 0 NA 1 ...\n $ eggplantD : int  0 0 NA 0 2 2 2 0 NA 2 ...\n $ moussaka  : int  1 1 1 1 1 1 1 1 1 1 ...\n $ moussakaD : int  2 1 0 0 2 2 1 3 2 2 ...\n $ orzo      : int  1 1 1 0 1 1 1 1 1 1 ...\n $ orzoD     : int  3 3 1 0 2 2 2 3 2 3 ...\n $ greeksal  : int  1 1 NA 0 1 1 1 1 1 1 ...\n $ greeksalD : int  1 3 NA 0 2 2 2 2 2 2 ...\n $ bread     : int  1 1 1 0 1 1 1 1 1 1 ...\n $ breadD    : int  2 3 1 0 2 2 2 2 2 2 ...\n $ dessert   : int  1 1 NA 0 1 1 0 1 NA NA ...\n $ dessertD  : int  2 3 NA 0 2 2 0 1 NA NA ...\n $ champagne : int  1 1 0 1 1 1 1 1 1 1 ...\n $ champagneD: int  1 1 0 3 1 1 2 1 1 1 ...\n $ beer      : int  1 0 0 1 1 1 NA 1 NA 1 ...\n $ beerD     : int  3 0 0 3 2 3 NA 1 NA 2 ...\n $ redwine   : int  0 1 0 1 0 0 1 0 1 0 ...\n $ redwineD  : int  0 3 0 3 0 0 2 0 2 0 ...\n $ whitewine : int  0 0 0 1 1 1 1 1 NA 0 ...\n $ whitewineD: int  0 0 0 3 3 2 1 3 NA 0 ...\n $ dayonset  : chr  \"6oct2024\" \"\" \"\" \"\" ...\n\n\nCode\nskimr::skim(copdata)\n\n\n\nData summary\n\n\nName\ncopdata\n\n\nNumber of rows\n397\n\n\nNumber of columns\n40\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n37\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n8\n8\n0\n397\n0\n\n\nsex\n0\n1\n4\n6\n0\n2\n0\n\n\ndayonset\n0\n1\n0\n8\n175\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1.00\n18.57\n9.92\n8\n16\n17\n18\n180\n▇▁▁▁▁\n\n\ngroup\n0\n1.00\n0.96\n0.20\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nclass\n36\n0.91\n1.94\n0.84\n1\n1\n2\n3\n3\n▇▁▆▁▇\n\n\ndiarrhoea\n141\n0.64\n0.82\n0.39\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nbloody\n200\n0.50\n0.03\n0.17\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nvomiting\n179\n0.55\n0.30\n0.46\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nabdo\n152\n0.62\n0.85\n0.35\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nnausea\n170\n0.57\n0.76\n0.43\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nfever\n223\n0.44\n0.26\n0.44\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nheadache\n174\n0.56\n0.63\n0.48\n0\n0\n1\n1\n1\n▅▁▁▁▇\n\n\njointpain\n207\n0.48\n0.16\n0.37\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nstarthour\n177\n0.55\n12.49\n4.92\n3\n9\n9\n15\n21\n▁▇▁▆▃\n\n\nmeal\n9\n0.98\n0.97\n0.17\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nfeta\n16\n0.96\n0.71\n0.45\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\nfetaD\n16\n0.96\n1.32\n1.00\n0\n0\n2\n2\n3\n▆▅▁▇▂\n\n\nsardines\n17\n0.96\n0.67\n0.47\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\nsardinesD\n17\n0.96\n1.34\n1.04\n0\n0\n2\n2\n3\n▆▂▁▇▂\n\n\neggplant\n30\n0.92\n0.59\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\neggplantD\n30\n0.92\n1.14\n1.05\n0\n0\n1\n2\n3\n▇▂▁▇▂\n\n\nmoussaka\n15\n0.96\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nmoussakaD\n14\n0.96\n1.83\n0.91\n0\n1\n2\n2\n3\n▂▃▁▇▃\n\n\norzo\n15\n0.96\n0.88\n0.32\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\norzoD\n15\n0.96\n1.81\n0.91\n0\n1\n2\n2\n3\n▂▃▁▇▃\n\n\ngreeksal\n24\n0.94\n0.57\n0.50\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\ngreeksalD\n24\n0.94\n1.08\n1.06\n0\n0\n1\n2\n3\n▇▂▁▆▂\n\n\nbread\n18\n0.95\n0.91\n0.29\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nbreadD\n18\n0.95\n1.75\n0.71\n0\n2\n2\n2\n3\n▁▂▁▇▁\n\n\ndessert\n42\n0.89\n0.42\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▆\n\n\ndessertD\n42\n0.89\n0.83\n1.06\n0\n0\n0\n2\n3\n▇▁▁▃▁\n\n\nchampagne\n25\n0.94\n0.87\n0.34\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nchampagneD\n25\n0.94\n1.37\n0.93\n0\n1\n1\n2\n3\n▂▇▁▂▃\n\n\nbeer\n30\n0.92\n0.78\n0.42\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nbeerD\n35\n0.91\n1.94\n1.23\n0\n1\n3\n3\n3\n▃▂▁▂▇\n\n\nredwine\n50\n0.87\n0.23\n0.42\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nredwineD\n52\n0.87\n0.45\n0.92\n0\n0\n0\n0\n3\n▇▁▁▁▁\n\n\nwhitewine\n31\n0.92\n0.73\n0.45\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\nwhitewineD\n36\n0.91\n1.58\n1.21\n0\n0\n2\n3\n3\n▆▅▁▅▇\n\n\n\n\n\nCode\nnames(copdata)\n\n\n [1] \"id\"         \"sex\"        \"age\"        \"group\"      \"class\"     \n [6] \"diarrhoea\"  \"bloody\"     \"vomiting\"   \"abdo\"       \"nausea\"    \n[11] \"fever\"      \"headache\"   \"jointpain\"  \"starthour\"  \"meal\"      \n[16] \"feta\"       \"fetaD\"      \"sardines\"   \"sardinesD\"  \"eggplant\"  \n[21] \"eggplantD\"  \"moussaka\"   \"moussakaD\"  \"orzo\"       \"orzoD\"     \n[26] \"greeksal\"   \"greeksalD\"  \"bread\"      \"breadD\"     \"dessert\"   \n[31] \"dessertD\"   \"champagne\"  \"champagneD\" \"beer\"       \"beerD\"     \n[36] \"redwine\"    \"redwineD\"   \"whitewine\"  \"whitewineD\" \"dayonset\"  \n\n\nLet’s explore and manage some variables in detail.\n\nAge\nThrough visual exploration of the age histogram we see that there is at least one very high value, likely implausible. You can then create a cross-tabulation of variables age and group to have a better idea of how your data looks like.\n\n\nCode\n# Have a look at the histogram  \nhist(copdata$age)   \n\n\n\n\n\nCode\n# Create cross-tab with the group variable:  \njanitor::tabyl(dat = copdata, \n               var1 = age, \n               var2 = group)\n\n\n\n\n  \n\n\n\nNote that group is coded as 0 and 1, and these may be difficult to interpret when they mean something other than “no” and “yes”, respectively. From the codebook, you know that teachers are represented by 0, and students by 1. Let’s change this to make our lives easier:\n\n\nCode\n# Convert group to a factor and label 0 as teacher, 1 as student:\ncopdata &lt;- copdata %&gt;% \n  mutate(group = factor(group, \n                        labels = c(\"teacher\", \"student\")))\n\n\nNow, have a look at your cross-tab again:\n\n\nCode\njanitor::tabyl(dat = copdata, \n               var1 = age, \n               var2 = group) \n\n\n\n\n  \n\n\n\nWith this table, we can more easily identify ages that are likely to be typographic errors. Specifically:\n\nThere is one teacher aged 16 (likely digit reversal - should be 61)\nThere is one student aged 8 (likely missing a digit - should be 18)\nThere is one student aged 180 (likely has an extra digit - should be 18)\n\nAssuming you have contacted the school to make sure your suspicions about the actual ages are correct, we can now correct them, using case_when(). We create logical conditions to identify the incorrect ages, combining the values for age with the group they belong to:\n\n\nCode\n# Update incorrect ages to the correct values with case_when:  \ncopdata &lt;- copdata %&gt;%       \n  mutate(age =                         \n           case_when(                            \n             # Where respondent is 16 and a teacher, change age to 61:\n             age == 16 & group == \"teacher\" ~ 61,              \n             # where respondent is 8 or 180 and a student, change age to 18:\n             age == 8 & group == \"student\" ~ 18,              \n             age == 180 & group == \"student\" ~ 18,              \n             # Keep remaining values as is:              \n             .default = as.numeric(age)   \n             # if .default is not working, try:\n             # TRUE ~ age\n             )                    \n         ) \n\n\n\n\n\n\n\n\nCreate summary table for the dose response columns (those finishing with a capital “D”) to have a look at their distribution.\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse gtsummary::tbl_summary().\n\n\n\n\n\nCode\n#| label: check_dose_cols\n#| tbl-cap: no caption\n\n# Create summary table for dose response columns: \ndrtable &lt;- copdata %&gt;%       \n  # Select all the columns with column names that end in upper case 'D':   \n  select(ends_with(\"D\", ignore.case = FALSE)) %&gt;%       \n  # Create the summary table, excluding missing values:   \n  gtsummary::tbl_summary(missing = \"no\") \n\n  # Print the summary table: \ndrtable\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 3971\n    \n  \n  \n    fetaD\n\n        0\n110 (29%)\n        1\n78 (20%)\n        2\n155 (41%)\n        3\n38 (10.0%)\n    sardinesD\n\n        0\n125 (33%)\n        1\n35 (9.2%)\n        2\n184 (48%)\n        3\n36 (9.5%)\n    eggplantD\n\n        0\n151 (41%)\n        1\n41 (11%)\n        2\n147 (40%)\n        3\n28 (7.6%)\n    moussakaD\n\n        0\n42 (11%)\n        1\n70 (18%)\n        2\n184 (48%)\n        3\n87 (23%)\n    orzoD\n\n        0\n44 (12%)\n        1\n70 (18%)\n        2\n183 (48%)\n        3\n85 (22%)\n    greeksalD\n\n        0\n162 (43%)\n        1\n52 (14%)\n        2\n126 (34%)\n        3\n33 (8.8%)\n    breadD\n\n        0\n35 (9.2%)\n        1\n51 (13%)\n        2\n267 (70%)\n        3\n26 (6.9%)\n    dessertD\n\n        0\n206 (58%)\n        1\n33 (9.3%)\n        2\n87 (25%)\n        3\n29 (8.2%)\n    champagneD\n\n        0\n49 (13%)\n        1\n208 (56%)\n        2\n45 (12%)\n        3\n70 (19%)\n    beerD\n\n        0\n81 (22%)\n        1\n41 (11%)\n        2\n57 (16%)\n        3\n183 (51%)\n    redwineD\n\n        0\n266 (77%)\n        1\n31 (9.0%)\n        2\n21 (6.1%)\n        3\n27 (7.8%)\n    whitewineD\n\n        0\n100 (28%)\n        1\n73 (20%)\n        2\n67 (19%)\n        3\n121 (34%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "SimOb_RInject09.html#modify-variables-format",
    "href": "SimOb_RInject09.html#modify-variables-format",
    "title": "Inject 09: Data import and cleaning",
    "section": "3.4. Modify variables format",
    "text": "3.4. Modify variables format\nThere are some “column types” you would like to modify because either R needs some specific types of data when working with certain variables, or because it will be easier for you to visualise and interpret the data. For example, the variable “group” is encoded as 0 and 1, when you create a table later on, you don’t want to see 0’s and 1’s because that doesn’t mean anything. It is better to change this variable to a factor, with explicit labels, so they actually mean something when they come out in your table.\n\n\n\n\n\nYou can use mutate to modify the type of the following variables:\n\nTable 1: Variable types to modify\n\n\n\n\n\n\n\n\nVariable name\nOriginal\nDesired\nHint\n\n\n\n\nsex\ncharacter\nfactor\nmutate(), as.factor()\n\n\nclass\ninteger\nfactor\nmutate(), as.factor()\n\n\nAll the clinical symptom variables\ninteger\nlogical\nmutate(across()), as.logical()\n\n\nAll the food variables representing the amount of specific foods eaten (those finishing with a capital “D”)\ninteger\nfactor\nmutate(across()), as.factor()\n\n\ndayonset\ncharacter\ndate\nlubridate::dmy()\n\n\nstarthour and dayonset together\ninteger (starthour)\ndate (dayonset)\nPOSIXct, POSIXt\nlubridate::ymd_h() could have inside stringr::str_glue() with dayonset and starthour\n\n\n\n\nSex, group and class\nLet’s start transforming one-by-one the first two variables in the table: sex, and class.\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  dplyr::mutate(\n    sex = as.factor(sex),\n    class = as.factor(class))\n\n\n\n\nSymptoms and Food variables\nFor these variables, we are going to show you a couple of different ways to carry out the same variable type transformation in a set of variables, so you don’t need to do one variable at a time. We are showing you these ways so you see alternative ways to do the same thing.\n\nFor the variables that are clinical symptoms, we will list them one by one and show you the use of mutate(across( )).\n\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  dplyr::mutate(\n    # clinical symptoms\n    across(.cols = c(diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain), \n           .fns = ~ as.logical(.)\n           )\n    )\n\n\n\nFor the variables that are food doses, we will show you how to first create a vector of names, following by using mutate(across(all_of( ))) on this vector.\n\n\n\nCode\n# Create a vector with all the food variables representing the amount of specific foods items eaten (those finishing with a capital \"D\")\n# One way of doing it:\nfood_dose &lt;- copdata %&gt;% \n    dplyr::select(\n      ends_with(\"D\", ignore.case = FALSE)) %&gt;% \n    names()\n\n# Another way of doing it:\n# food_dose &lt;- c(\"fetaD\", \"sardinesD\", \"eggplantD\", \"moussakaD\", \n#                 \"orzoD\", \"greeksalD\", \"dessertD\", \"breadD\", \n#                 \"champagneD\", \"beerD\", \"redwineD\", \"whitewineD\")\n\n\ncopdata &lt;- copdata %&gt;% \n  dplyr::mutate(\n    # food dose variables\n    across(.cols = all_of(food_dose), \n           .fns = ~as.factor(.))) \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe tilde (~) above is used to apply the transformation as.logical(.) to each selected column, which in our case is either all columns included in food_items and food_dose.\n\n\n\n\n\nDate and time variables\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhy may you want to transform the variable starthour to date-time?\n\n\n\n\n\n\n\n\nYou can use lubridate::dmy() to mutate the dayonset variable into a date variable. Note that we are using the function dmy() because dates are formatted as day, then month (abbreviated character string), then year (i.e. “12nov2006”).\n\n\nCode\n# Have a look at how the data is stored\nhead(copdata$dayonset)\n\n\n[1] \"6oct2024\" \"\"         \"\"         \"\"         \"6oct2024\" \"7oct2024\"\n\n\nCode\nclass(copdata$dayonset)\n\n\n[1] \"character\"\n\n\nCode\n# Update copdata:\ncopdata &lt;- copdata %&gt;% \n  # Change column to date class:\n  dplyr::mutate(\n    dayonset = lubridate::dmy(dayonset))\n\n# Check class of updated column:\nclass(copdata$dayonset)\n\n\n[1] \"Date\"\n\n\nCode\n# Have a look at your data now:\nhead(copdata$dayonset)\n\n\n[1] \"2024-10-06\" NA           NA           NA           \"2024-10-06\"\n[6] \"2024-10-07\"\n\n\nHaving a variable that defines “time” in an outbreak investigation can be very useful when creating a case definition. An hour of the day, without a date associated with it doesn’t help you much, thus, you should merge together day and time of onset of symptoms into a single variable. Moreover, you will be using this combined variable later on to estimate an incubation period and create your epicurve. We can combine these two variables by using the lubridate::ymd_h() function.\nBefore we proceed, it would be wise to check if any respondents have a value for dayonset but not starthour, or vice versa. The lubridate date-time conversion functions do not have an explicit argument for dealing with missing values, but the truncated = … argument can help prevent spurious date-times being derived from a date-time combination where one value is missing.\nWe can check if we have any missing values by cross-tabulating starthour with dayonset:\n\n\nCode\n# Cross-tabulate dayonset with starthour:\njanitor::tabyl(dat = copdata, \n               var1 = starthour, \n               var2 = dayonset)\n\n\n\n\n  \n\n\n\nThis shows us that there are two respondents who had an onset date, but are missing onset time (starthour). Since starthour is represented by 1 - 2 digits, we can specify that we want lubridate to also parse date-time combinations that are truncated by up to two digits:\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  # Combine dayonset and starthour in a new date time variable:\n  mutate(onset_datetime = \n           lubridate::ymd_h(\n             str_glue(\"{dayonset}, {starthour}\"), \n                                           # Deal with missing starthour:\n                                           truncated = 2))\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `onset_datetime = lubridate::ymd_h(str_glue(\"{dayonset},\n  {starthour}\"), truncated = 2)`.\nCaused by warning:\n!  175 failed to parse.\n\n\nNote that we needed to use str_glue() to concatenate dayonset and starthour together before we could convert the variable to a date-time object. This is because the ymd_h() function expects a single character string, containing both the date and the time, as input.\nThe argument truncated = 2 will result in dates with missing starthour still being converted to date-time, with the missing time being set to 00:00 (midnight). Whether you want to deal with missing starthour in this way or prefer to code these date-times as NA will depend on how you want them to be represented in your analysis.\nNow we can check that everything in the new combined date-time variable has parsed correctly:\n\n\nCode\nhead(copdata$dayonset)\n\n\n[1] \"2024-10-06\" NA           NA           NA           \"2024-10-06\"\n[6] \"2024-10-07\"\n\n\nCode\nhead(copdata$starthour)\n\n\n[1]  9 NA NA NA 15 15\n\n\nCode\nhead(copdata$onset_datetime)\n\n\n[1] \"2024-10-06 09:00:00 UTC\" NA                       \n[3] NA                        NA                       \n[5] \"2024-10-06 15:00:00 UTC\" \"2024-10-07 15:00:00 UTC\""
  },
  {
    "objectID": "SimOb_RInject09.html#export-clean-data",
    "href": "SimOb_RInject09.html#export-clean-data",
    "title": "Inject 09: Data import and cleaning",
    "section": "3.5. Export clean data",
    "text": "3.5. Export clean data\nSave the cleaned data set before proceeding with using your case definition to identify cases in your dataset. Use the .rds format, as it preserves column classes. This ensures you will have only minimal cleaning to do after importing the data into R at the next inject.\nSave your clean data as a new file “Copenhagen_clean1_YOURINITIALS.rds”, under the data folder of your Rproject.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse rio::export().\n\n\n\n\n\nCode\nrio::export(x = copdata, \n            file = here::here(\"data\", \"Copenhagen_clean1_2024.rds\"))"
  },
  {
    "objectID": "SimOb_RInject15.html",
    "href": "SimOb_RInject15.html",
    "title": "Stratified analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nConsider the effect of confounding and effect modification on the association between exposure and disease,\nPerform stratified analysis using the Mantel-Haenszel approach\n\nThe use of stratified analysis, is the first step to identify confounding factors and effect modifiers one by one (after, of course, thinking which variables could potentially be confounders or effect modifiers). As the final step, you will be using Regression Models to account for confounding and check for effect modification. We will see these with you in the Multivariable Module (MVA), next year."
  },
  {
    "objectID": "SimOb_RInject15.html#install-packages-and-load-libraries",
    "href": "SimOb_RInject15.html#install-packages-and-load-libraries",
    "title": "Stratified analysis",
    "section": "3.2. Install packages and load libraries",
    "text": "3.2. Install packages and load libraries\n\n\nCode\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales,\n               EpiStats)"
  },
  {
    "objectID": "SimOb_RInject15.html#import-your-data",
    "href": "SimOb_RInject15.html#import-your-data",
    "title": "Stratified analysis",
    "section": "3.3. Import your data",
    "text": "3.3. Import your data\n\n\nCode\n# Import the raw data set: \ncopdata &lt;- rio::import(here::here(\"data\", \"Copenhagen_clean2_2024.rds\"))"
  },
  {
    "objectID": "SimOb_RInject15.html#risk-ratio",
    "href": "SimOb_RInject15.html#risk-ratio",
    "title": "Inject 14: Stratified analysis",
    "section": "3. Risk Ratio",
    "text": "3. Risk Ratio\n\na) Veal as exposure of interest, stratified by having eaten pasta\n\n\nCode\nstratall &lt;- copdata %&gt;% \n  # Mutate across to convert cases to numeric:\n  mutate(across(.cols = case, \n                .fns = ~ as.numeric(.)))\n\n# Pass data to the csinter function:\npastastrata &lt;- csinter(x = stratall, \n                       cases = \"case\", \n                       exposure = \"veal\", \n                       by = \"pasta\")\n\npastastrata\n\n\n$df1\n  CSInter case - veal by(pasta) Total Cases Risk %          P.est. Stats\n1                     pasta = 1   338  &lt;NA&gt;     NA Risk difference  0.10\n2                       Exposed   330   198  60.00      Risk Ratio  1.20\n3                     Unexposed     8     4  50.00 Attrib.risk.exp  0.17\n4                                  NA  &lt;NA&gt;     NA Attrib.risk.pop  0.16\n5                     pasta = 0    36  &lt;NA&gt;     NA Risk difference  0.02\n6                       Exposed     8     3  37.50      Risk Ratio  1.05\n7                     Unexposed    28    10  35.71 Attrib.risk.exp  0.05\n8                                  NA  &lt;NA&gt;     NA Attrib.risk.pop  0.01\n9           Missing / Missing %     3  0.8%     NA            &lt;NA&gt;    NA\n  95%CI-ll 95%CI-ul\n1    -0.25     0.45\n2     0.60     2.41\n3    -0.68     0.59\n4       NA       NA\n5    -0.36     0.40\n6     0.38     2.92\n7    -1.65     0.66\n8       NA       NA\n9       NA       NA\n\n$df2\n                  Point Estimate Chi2 p.value  Stats 95%CI-ll 95%CI-ul\n1      Woolf test of homogeneity 0.04   0.833     NA       NA       NA\n2              Crude RR for veal   NA      NA   1.53     1.01     2.32\n3  MH RR veal adjusted for pasta   NA      NA   1.15     0.64     2.04\n4 Adjusted/crude relative change   NA      NA -25.08       NA       NA\n\n\nLet’s check if pasta is associated with veal (if we are thinking veal may be a confounder, we need to see if there is an association between the potential confounder (veal) and the exposure (pasta)):\n\n\nCode\n# Perform Wilcoxon rank sum test on pasta and veal:\nwilcox.test(pasta ~ veal, \n            data = copdata)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  pasta by veal\nW = 1496, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nc) Champagne as exposure of interest, stratified by having eaten pasta\n\n\nCode\n# Pass data to the csinter function:\nchampstrata &lt;- csinter(x = stratall, \n                       cases = \"case\", \n                       exposure = \"champagne\", \n                       by = \"pasta\")"
  },
  {
    "objectID": "SimOb_RInject11.html",
    "href": "SimOb_RInject11.html",
    "title": "Laboratory data and descriptive analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nMerge two datasets using a common column.\nDiscuss which descriptive statistics would you use to describe the cases\nDescribe the cases by person and place (this is an outbreak in a high school, so we won’t explore “place” this time!)\nGenerate preliminary hypotheses bases on the descriptions."
  },
  {
    "objectID": "SimOb_RInject11.html#install-packages-and-load-libraries",
    "href": "SimOb_RInject11.html#install-packages-and-load-libraries",
    "title": "Inject 11: Descriptive analysis",
    "section": "",
    "text": "Code\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "SimOb_RInject11.html#import-your-data",
    "href": "SimOb_RInject11.html#import-your-data",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.2 Import your data",
    "text": "3.2 Import your data\n\n\nCode\n# Import the clean data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"Copenhagen_clean2_2024.rds\")) \nlab &lt;- rio::import(here::here(\"data\", \"lab_pos.xlsx\"))"
  },
  {
    "objectID": "SimOb_RInject11.html#time",
    "href": "SimOb_RInject11.html#time",
    "title": "Inject 11: Descriptive analysis",
    "section": "3. Time",
    "text": "3. Time\n\na) Incubation period histogram\n\n\nCode\n#| label: inc_time\n\n# Create a dataset with only cases\ncases &lt;- copdata %&gt;% \n  filter(case == TRUE)\n\nincplot &lt;- cases %&gt;% \n  # Create an empty ggplot frame:\n  ggplot() +\n  # Add a histogram of incubation:\n  geom_histogram(\n    mapping = aes(x = incubation), \n    # Set bin widths to 6 hours:\n    binwidth = 6) +\n  # Adapt scale to better fit data\n  scale_x_continuous(breaks = seq(0, 48, 6)) + \n  # Label x and y axes:\n  labs(x = \"Incubation period in 6-hour bins\",\n       y = \"Number of cases\")\n\n# Print plot:\nincplot\n\n\n\n\n\n\n\nb) Epicurve for date and time of onset\n\n\nCode\n# Create a vector with sequences every 6h from the first to the last case\nbreaks_6h &lt;- seq(from = min(cases$onset_datetime, na.rm = TRUE),\n                 to = max(cases$onset_datetime, na.rm = TRUE),\n                 by = \"6 hours\")\n\n# Fetch cases data:\nepicurve_datetime &lt;- cases %&gt;%  \n  # Add factor onset_datetime to ggplot aesthetic:\n  ggplot(\n    mapping = aes(x = onset_datetime)) + \n  # Add geom_histogram:\n  geom_histogram(\n    # Apply the vector of requences created above\n    breaks = breaks_6h) +\n  # Adapt scale to data and adjust axis label angle:\n  scale_x_datetime(\n    date_breaks = \"6 hours\",\n    labels = label_date_short()) +\n  # Update x and y axis labels:\n  labs(x = \"Date and time of onset symptoms\", \n       y = \"Number of cases\") +\n  # Remove unnecessary grid lines:\n  theme_bw()\n\n# Print epicurve:\nepicurve_datetime\n\n\n\n\n\n\n\nCode\nepicurve_strata &lt;- cases %&gt;% \n  # Add factor onset_day to ggplot aesthetic:\n  ggplot(\n    mapping = aes(x = onset_datetime, fill = group)) + \n  # Add nicer fill colours:\n  scale_fill_manual(values = c(\"darkred\", \"lightblue\")) +\n    # Add geom_histogram:\n  geom_histogram(\n    # Apply the vector of requences created above\n    breaks = breaks_6h) +\n  # Adjust x axis scales to a suitable unit:\n  scale_x_datetime(\n    date_breaks = \"6 hours\", \n    labels = label_date_short()) +\n  # Update x and y axis labels:\n  labs(x = \"Date and time of onset\", \n       y = \"Number of cases\", \n       fill = \"Group\", \n       title = \"Epicurve of the outbreak, stratified by sex\",\n       subtitle = str_glue(\"Copenhagen, November 2006, N = {sum(copdata$case)}\")) +\n  # Stratify by sex:\n  facet_wrap(facets = \"sex\",\n             ncol = 2) +\n  # Add theme:\n  theme_bw()\n\n# Print epicurve:\nepicurve_strata"
  },
  {
    "objectID": "SimOb_RInject11.html#person",
    "href": "SimOb_RInject11.html#person",
    "title": "Inject 11: Descriptive analysis",
    "section": "4. Person",
    "text": "4. Person\n\na) Cross-tabulation of cases with group\n\n\nCode\ncopdata %&gt;% \n  janitor::tabyl(case, group) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() \n\n\n\n\n  \n\n\n\n\n\nb) Cross-tabulation of cases with sex\n\n\nCode\ncopdata %&gt;% \n  janitor::tabyl(case, sex) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() \n\n\n\n\n  \n\n\n\n\n\nc) Extra - Age-sex pyramid of cases\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  # Create age categories:\n  mutate(age_cat = epikit::age_categories(\n    # Name of age column:\n    x = age, \n    # Define the age categories:\n    breakers = c(0, 10, 16, 18, 20, 50, 70)\n    )\n  )\n\n\n# Check age categories:\njanitor::tabyl(copdata, age_cat)\n\n\n\n\n  \n\n\n\nCode\n# Pipe copdata:\nagesex &lt;- copdata %&gt;% \n  # Filter for cases only:\n  filter(case == TRUE) %&gt;% \n  # Create age sex pyramid:\n  apyramid::age_pyramid(\n  # Specify column containing age categories:\n    age_group = \"age_cat\",\n    # Specify column containing sex:\n    split_by = \"sex\", \n    # Don't show midpoint on the graph:\n    show_midpoint = FALSE\n    )\n\n# Print plot:\nagesex\n\n\n\n\n\n(Hint: change show_midpoint = FALSE to TRUE to see skewedness in the data patterns more easily)."
  },
  {
    "objectID": "SimOb_RInject11.html#symptoms",
    "href": "SimOb_RInject11.html#symptoms",
    "title": "Inject 11: Descriptive analysis",
    "section": "5. Symptoms",
    "text": "5. Symptoms\n\nSummary table of symptoms, stratified by case definition\n\n\n\nCode\n# Create summary table:\ntabsymptoms &lt;- copdata %&gt;% \n    # Select person characteristics to summarise:\n  select(case, diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain) %&gt;% \n  # transform clinical symptoms to factors, so NA can be accounted properly in the table\n  dplyr::mutate(\n    across(.cols = c(diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain), \n           .fns = ~as.factor(.))) %&gt;%\n  # Make NA a explicit level of factor variables\n  dplyr::mutate(\n    across(.cols = c(diarrhoea, bloody, vomiting,\n           abdo, nausea, fever,headache, jointpain),\n           .fns = ~forcats::fct_na_value_to_level(.))) %&gt;% \n    \n  # Create the summary table:\n  gtsummary::tbl_summary(\n    # Stratify by case:\n    by = case, \n    # Calculate row percentages:\n    percent = \"column\",\n    # Create nice labels:\n    label  = list(\n      diarrhoea   ~ \"Diarrhoea\",                           \n      bloody      ~ \"Dysentary\",\n      vomiting    ~ \"Vomiting\",\n      abdo        ~ \"Abdominal pain\",\n      nausea      ~ \"Nausea\", \n      fever       ~ \"Fever\", \n      headache    ~ \"Headache\", \n      jointpain   ~ \"Joint pain\")\n    \n  ) %&gt;% \n  \n  # Add totals:\n  add_overall() %&gt;% \n  # Make variable names bold and italics:\n  bold_labels() %&gt;% \n  italicize_labels() %&gt;% \n  # Modify header:\n  modify_header(\n    label = \"**Characteristic**\",\n    stat_0 = \"**Overall**\\n **N** = {N}\",\n    stat_1 = \"**Non-case**\\n **N** = {n}\",\n    stat_2 = \"**Case**\\n **N** = {n}\", \n    )\n\n# Print the table:\ntabsymptoms\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Overall\nN = 3771\n      Non-case\nN = 1611\n      Case\nN = 2161\n    \n  \n  \n    Diarrhoea\n\n\n\n        FALSE\n46 (18%)\n40 (100%)\n6 (2.8%)\n        TRUE\n206 (82%)\n0 (0%)\n206 (97%)\n    Dysentary\n\n\n\n        FALSE\n189 (97%)\n42 (100%)\n147 (97%)\n        TRUE\n5 (2.6%)\n0 (0%)\n5 (3.3%)\n    Vomiting\n\n\n\n        FALSE\n149 (69%)\n42 (100%)\n107 (62%)\n        TRUE\n66 (31%)\n0 (0%)\n66 (38%)\n    Abdominal pain\n\n\n\n        FALSE\n35 (14%)\n6 (12%)\n29 (15%)\n        TRUE\n207 (86%)\n44 (88%)\n163 (85%)\n    Nausea\n\n\n\n        FALSE\n55 (25%)\n12 (26%)\n43 (24%)\n        TRUE\n169 (75%)\n34 (74%)\n135 (76%)\n    Fever\n\n\n\n        FALSE\n127 (74%)\n32 (80%)\n95 (73%)\n        TRUE\n44 (26%)\n8 (20%)\n36 (27%)\n    Headache\n\n\n\n        FALSE\n83 (38%)\n11 (25%)\n72 (41%)\n        TRUE\n137 (62%)\n33 (75%)\n104 (59%)\n    Joint pain\n\n\n\n        FALSE\n159 (85%)\n32 (84%)\n127 (85%)\n        TRUE\n29 (15%)\n6 (16%)\n23 (15%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\nBar plot of symptoms stratified by case definition\n\n\n\nCode\n# Create list of symptom variables:\nsymptoms &lt;- c(\"diarrhoea\", \n              \"bloody\", \n              \"vomiting\", \n              \"abdo\", \n              \"nausea\", \n              \"fever\", \n              \"headache\", \n              \"jointpain\")\n\n# Create nice labels for case definition:\ncaselabs &lt;- ggplot2::as_labeller(c(`FALSE` = \"Non-case\", \n                                   `TRUE` = \"Case\"))\n# Select variables and cases:\nsymptom_bar &lt;- copdata %&gt;% \n  # Select symptom columns:\n  select(case, c(all_of(symptoms))) %&gt;%\n  # Drop NAs:\n  drop_na() %&gt;% \n  # Reshape (pivot longer):\n  pivot_longer(!case, \n               names_to = \"Symptoms\", \n               values_drop_na = TRUE) %&gt;% \n  # Keep only TRUE values:\n  filter(value == TRUE) %&gt;% \n \n   # Group by symptoms and case:\n  group_by(Symptoms, case) %&gt;% \n  # Count for each symptom by case:\n  dplyr::summarise(count = n()) %&gt;% \n  # Create plot:\n  ggplot(\n    mapping = aes(\n    # Order symptom bars so most common ones are ontop:\n    x = reorder(Symptoms, desc(count), decreasing = TRUE), \n    y = count)) +\n  # Display bars as proportions\n  geom_bar(stat = \"identity\") +\n  # Update x axis label:\n  xlab(\"Symptoms\") +\n  # Update y axis label:\n  ylab(\"Proportion of respondents\") +\n  # Flip plot on its side so symptom labels are clear:\n  coord_flip() +\n  # Facet the plot by (labelled) case:\n  facet_wrap(facets = \"case\",\n             labeller = caselabs,\n             ncol = 2)\n\n\n`summarise()` has grouped output by 'Symptoms'. You can override using the\n`.groups` argument.\n\n\nCode\n# Print plot:\nsymptom_bar"
  },
  {
    "objectID": "SimOb_RInject11.html#attack-proportions",
    "href": "SimOb_RInject11.html#attack-proportions",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.7 Attack proportions",
    "text": "3.7 Attack proportions\n\na) Calculate the overall attack proportions (percentage of cases among the total observed individuals). You could use tabyl().\n\n\nCode\n# Create table of case status:\ntotal_ap &lt;- tabyl(copdata, case) %&gt;% \n # Add row totals:\n  adorn_totals(where = \"row\") %&gt;% \n  # Add percentages with 1 digit after the decimal point:\n  adorn_pct_formatting(digits = 1) %&gt;% \n  # Filter to rows where case is TRUE:\n  filter(case == TRUE) %&gt;% \n  # Select the column percent:\n  select(percent) %&gt;% \n  # Extract (pull) the value from this cell:\n  pull()\n\n# Print result:\ntotal_ap\n\n\n[1] \"57.3%\"\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat can you infer from the overall attack proportion about this outbreak and possible vehicles/exposures?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above questions, have a look here\n\n\n\n\n\nThe overall attack proportion is 57.3%. This means that more than half of the people who ate a meal were cases!\n\n\n\n\n\nb) Calculate attack proportions for group, class and sex by case status. You could use tabyl() (as you did in 3.4) or gtsummary::tbl_summary.\n\n\nCode\n# Table to calculate attack proportions:\nattack_prop &lt;- copdata %&gt;% \n  # Select columns:\n  select (case, class, group, sex) %&gt;% \n  \n  # Create table:\n  tbl_summary(\n    # Stratified by case\n    by = case,\n    # with row percentages\n    percent = \"row\") %&gt;%\n  \n  # Add totals:\n  add_overall() %&gt;%\n  \n  # Make variable names bold and italics:\n  bold_labels() %&gt;% \n  italicize_labels() %&gt;% \n  \n  # Modify header:\n  modify_header(\n    label = \"**Characteristic**\",\n    stat_0 = \"**Overall** **N** = {N}\",\n    stat_1 = \"**Non-case** **N** = {n}\",\n    stat_2 = \"**Case** **N** = {n}\"\n  )\n\n\n# Print table:\nattack_prop\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Overall N = 3771\n      Non-case N = 1611\n      Case N = 2161\n    \n  \n  \n    class\n\n\n\n        1\n131 (100%)\n63 (48%)\n68 (52%)\n        2\n101 (100%)\n44 (44%)\n57 (56%)\n        3\n111 (100%)\n38 (34%)\n73 (66%)\n        Unknown\n34\n16\n18\n    group\n\n\n\n        teacher\n15 (100%)\n9 (60%)\n6 (40%)\n        student\n362 (100%)\n152 (42%)\n210 (58%)\n    sex\n\n\n\n        female\n213 (100%)\n96 (45%)\n117 (55%)\n        male\n164 (100%)\n65 (40%)\n99 (60%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "SimOb_RInject10.html",
    "href": "SimOb_RInject10.html",
    "title": "Case Definition",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nApply case definition criteria to a dataset using logical arguments in R"
  },
  {
    "objectID": "SimOb_RInject10.html#install-packages-and-load-libraries",
    "href": "SimOb_RInject10.html#install-packages-and-load-libraries",
    "title": "Case Definition - Inj10",
    "section": "",
    "text": "# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "SimOb_RInject10.html#import-your-data",
    "href": "SimOb_RInject10.html#import-your-data",
    "title": "Case Definition",
    "section": "3.2 Import your data",
    "text": "3.2 Import your data\n\n\nCode\n# Import the clean data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"Copenhagen_clean1_2024.rds\"))"
  },
  {
    "objectID": "SimOb_RInject10.html#identify-cases",
    "href": "SimOb_RInject10.html#identify-cases",
    "title": "Case Definition - Inj10",
    "section": "3. Identify cases",
    "text": "3. Identify cases\n\na) Ate a meal at the school dinner\nKeep in your dataset only those who ate a meal.\n\ncopdata &lt;- copdata %&gt;% \n  filter(meal == TRUE)\n\n\n\nb) Fell ill after the start of the meal\nDefine “fell ill” as any person having had diarrhoea with OR without blood, OR vomiting. Note that we the concept of having eaten a meal is already included as per one of the steps above:\n\ncopdata &lt;- copdata %&gt;% \n  mutate(gastrosymptoms = case_when(\n    # Those had diarrhoea...\n    diarrhoea == TRUE |\n      #or bloody diarrhoea...\n    bloody == TRUE |\n      # or vomiting, are marked as TRUE (fell ill after the meal)\n    vomiting == TRUE ~ TRUE,\n    # The rest are FALSE. This includes those who ate a meal but had no symptoms (did not fell ill after the meal)\n    .default = FALSE)\n    )\n\n\n\nc) Fell ill within the time period of interest\nCreate a new meal_datetime variable as per 11 Nov 2006, at 18:00h:\n\n# Start with copdata:\ncopdata &lt;- copdata %&gt;% \n  # Create new column for meal date and time:\n  mutate(meal_datetime = lubridate::ymd_hm(\"2006-11-11 18:00\"))\n\nCalculate incubation time and its median:\n\ncopdata &lt;- copdata %&gt;% \n  mutate(incubation = onset_datetime - meal_datetime,\n         incubation = as.numeric (incubation))\n\n\nmedian(as.numeric(copdata$incubation), na.rm = TRUE)\n\n[1] 15\n\n\nWe see that the median incubation time is 15 hours. This is useful information, as incubation periods tend to be relatively pathogen-specific. We can now refine the case definition and limit the maximum incubation period from the meal time to 48 hours (2 days) after the meal, as the data points to a fast-acting bacterial toxin or a virus.\n\ncopdata &lt;- copdata %&gt;% \n  mutate(case = case_when(\n    # Those who had symptoms &lt;48h from the meal are cases (TRUE)\n    gastrosymptoms == TRUE & \n      onset_datetime &gt;= meal_datetime &\n      onset_datetime &lt;= (meal_datetime + days(2)) ~ TRUE,\n    # Those who had symptoms &gt;48h from the meal are non-cases (FALSE)\n    gastrosymptoms == TRUE & \n      onset_datetime &gt; (meal_datetime + days(2)) ~ FALSE,\n    # The rest are considered non-cases. Including, those who had no symptoms at all, who have missing data on the onset_datetime variable, or who had symptoms before eating the meal \n    .default = FALSE)\n  )\n\nNote that we may be incurring in misclassification bias with the code above. The last section indicates that if a person had clinical symptoms before eating the meal, they are considered as non-cases. However, it could be that a person had symptoms before the meal, and yet, still got infected by the pathogen when eating their meal (bad luck, we know…).\nMoreover, if you remember from inject 9, there were a couple of people with an dayonset, but no starthour. The code we used (lubridate::ymd_h with argument truncated = 2) results in dates with missing starthour being converted to date-time, with the missing time being set to 00:00 (midnight). This means that these two people don’t fulfill the case definition criteria because we marked their symptoms started early in the morning of Nov 11 (at 00:00), before the meal time (18:00), and thus, they did not “fell ill within the time period of interest”.\nThe two situations above are a reminder that you need to be both careful and aware of the implications of your data analysis decisions.\n\n# Tabulate cases:\njanitor::tabyl(dat = copdata, case)\n\n  case   n   percent\n FALSE 161 0.4270557\n  TRUE 216 0.5729443\n\n\nLet’s have a look at how many people ate a meal, had symptoms, and were considered as cases after applying our case definition:\n\ncopdata %&gt;% \n  summarise(atemeal = sum(meal == TRUE),\n            hadsympt = sum(gastrosymptoms == TRUE),\n            nb_cases = sum(case == TRUE)\n            )\n\n  atemeal hadsympt nb_cases\n1     377      216      216"
  },
  {
    "objectID": "SimOb_RInject14.html",
    "href": "SimOb_RInject14.html",
    "title": "Univariable analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nPerform hypothesis tests.\nEstimate risk ratios (also called relative risk) for categorical data.\nInterpret the univariable results.\n(Optional) Investigate dose-response relationships in categorical data.2. Story/plot description"
  },
  {
    "objectID": "SimOb_RInject14.html#install-packages-and-load-libraries",
    "href": "SimOb_RInject14.html#install-packages-and-load-libraries",
    "title": "Univariable analysis",
    "section": "3.1. Install packages and load libraries",
    "text": "3.1. Install packages and load libraries\n\n\nCode\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales,\n               EpiStats,\n               broom)"
  },
  {
    "objectID": "SimOb_RInject14.html#import-your-data",
    "href": "SimOb_RInject14.html#import-your-data",
    "title": "Univariable analysis",
    "section": "3.2. Import your data",
    "text": "3.2. Import your data\n\n\nCode\n# Import the raw data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"Copenhagen_clean2_2024.rds\"))"
  },
  {
    "objectID": "SimOb_RInject14.html#hypothesis-tests-for-other-variables",
    "href": "SimOb_RInject14.html#hypothesis-tests-for-other-variables",
    "title": "Univariable analysis",
    "section": "3.3. Hypothesis tests for other variables",
    "text": "3.3. Hypothesis tests for other variables\nCheck if the following variables are associated with being a case: age, sex, class and group.\n\na) age\nWith the Shapiro-Wilk test we check if the variables are following the normal distribution. The null hypothesis is that the data follow a normal distribution, therefore, rejecting the null hypothesis means that the data do not follow the normal distribution. A p-value below the cutoff for rejecting the null hypothesis, e.g., a p-value&lt;0.05 means that we reject the null hypothesis that the data follow the normal distribution. For age, the p-value is &lt;0.05, therefore we reject the null hypothesis that the data are normally distributed. As we see in the graph most frequently reported age is &lt;20 years.\n\n\nCode\n# Check if age overall follows a normal distribution:\nshapiro.test(copdata$age)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  copdata$age\nW = 0.31302, p-value &lt; 2.2e-16\n\n\nCode\n# Can simply have a look at\nhist(copdata$age)\n\n\n\n\n\nCode\n# Looking only at the students:\nstudents &lt;- copdata %&gt;% \n  filter(group == \"student\")\nhist(students$age)\n\n\n\n\n\nAge overall (nor within the students’ group) is not normally distributed.\nWe compare the age for cases and non-cases using the Wilcoxon test that is used when the data are not normally distributed. The null hypothesis is that there is no difference in the age between the two groups compared. Given that p-value&gt;0.05 we do not reject the null hypothesis.\n\n\nCode\n# Perform Wilcoxon rank sum test on age and sex:\nwilcox.test(age ~ case, \n            data = copdata)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age by case\nW = 15934, p-value = 0.1512\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nb) sex\n\n\nCode\ncopdata %&gt;% \n  select(sex, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      FALSE, N = 1611\n      TRUE, N = 2161\n      p-value2\n    \n  \n  \n    sex\n\n\n0.3\n        female\n96 (60%)\n117 (54%)\n\n        male\n65 (40%)\n99 (46%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson’s Chi-squared test\n    \n  \n\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do these results tell you - is there an association between sex and being a case?\nDo these results differ from what you expected when looking at the descriptive figures (case proportions stratified by sex, or the age sex pyramid)? If so, why do you think this is?\n\n\n\n\n\nc) class\n\n\nCode\ncopdata %&gt;% \n  select(class, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      FALSE, N = 1611\n      TRUE, N = 2161\n      p-value2\n    \n  \n  \n    class\n\n\n0.090\n        1\n63 (43%)\n68 (34%)\n\n        2\n44 (30%)\n57 (29%)\n\n        3\n38 (26%)\n73 (37%)\n\n        Unknown\n16\n18\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson’s Chi-squared test\n    \n  \n\n\n\n\nIn this case you have a 2x3 contingency table of class against disease status, we can use a chi-square here. P-value of the association between class and age is p-val = 0.09, suggesting that there is an association at the p-val = 0.20 level among at least one of the 3 different classes. Fellows may want to investigate this further, but in the remaining of the study this is not explored further.\nA hypothesis could be that one of the classes sat together and, for whatever reason, they ate more of the contaminated food item at those tables. This could be further studied if we had the spatial distribution of where the people sat at the dinner. Another hypothesis is that one of the classes differ from other classes in some characteristics that made them more susceptible or more exposed to the infected food item.\n\n\nd) group\n\n\nCode\ncopdata %&gt;% \n  select(group, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      FALSE, N = 1611\n      TRUE, N = 2161\n      p-value2\n    \n  \n  \n    group\n\n\n0.2\n        teacher\n9 (5.6%)\n6 (2.8%)\n\n        student\n152 (94%)\n210 (97%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson’s Chi-squared test\n    \n  \n\n\n\n\nP-value of the association between group and age is p-val = 0.2, suggesting that there may be an association at the p-val = 0.20 level. Explanations are like above, with variable class.\n\n\nLet’s do all together\n\n\nCode\ncopdata %&gt;% \n  select(sex, class, group, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      FALSE, N = 1611\n      TRUE, N = 2161\n      p-value2\n    \n  \n  \n    sex\n\n\n0.3\n        female\n96 (60%)\n117 (54%)\n\n        male\n65 (40%)\n99 (46%)\n\n    class\n\n\n0.090\n        1\n63 (43%)\n68 (34%)\n\n        2\n44 (30%)\n57 (29%)\n\n        3\n38 (26%)\n73 (37%)\n\n        Unknown\n16\n18\n\n    group\n\n\n0.2\n        teacher\n9 (5.6%)\n6 (2.8%)\n\n        student\n152 (94%)\n210 (97%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson’s Chi-squared test"
  },
  {
    "objectID": "SimOb_RInject14.html#risk-ratios",
    "href": "SimOb_RInject14.html#risk-ratios",
    "title": "Univariable analysis",
    "section": "3.4. Risk Ratios",
    "text": "3.4. Risk Ratios\nThe risk ratios of each food item (including the 2x2 table) are reported below. The output of the CS() command is two tables: one with the 2x2 table and one with the risk difference, the risk ratio and the attributable fraction among exposed as well as the attributable fraction among the population (and the confidence intervals for all the estimates). The Chi-square and the p-value are also reported. In the second part, a table with all the food items is printed including attack rates for exposed and unexposed as well as risk ratios and the 95% confidence intervals (CI ll and CI ul, for the lower and upper interval) and p-values.\n\na) Calculate 95% CI Risk Ratios for food\nTo see if food items (note these are categorical variables) are associated with being a case, calculate risk ratios and 95% confidence intervals for food items. You can calculate this individually for each food item (using CSTable()), or all at once (see hint below).\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nCreate a food_vars vector containing food variables of interest and use the function CSTable() of the EpiStats package.\nUsing this hint, you will create a table with the name of exposure variables, the total number of exposed, the number of exposed cases, the attack rate among the exposed, the total number of unexposed, the number of unexposed cases, the attack rate among the unexposed, risk ratios, 95% percent confidence intervals, and p-values. Amazing, isn’t it? Have a look at ??CSTable to learn more.\n\n\n\n\n\nCode\n# You could use the EpiStats package for each food item\nCS(copdata, \"case\", \"feta\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     156       115   271 0.58\nUnexposed    60        42   102 0.59\nTotal       216       157   373 0.58\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference          -0.01    -0.12     0.10\nRisk ratio                0.98     0.81     1.19\nPrev. frac. ex.           0.02    -0.19     0.19\nPrev. frac. pop           0.02       NA       NA\nchi2(1)                   0.05       NA       NA\nPr&gt;chi2                  0.826       NA       NA\n\n\nCode\nCS(copdata, \"case\", \"sardines\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     150       105   255 0.59\nUnexposed    65        52   117 0.56\nTotal       215       157   372 0.58\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference           0.03    -0.08     0.14\nRisk ratio                1.06     0.87     1.28\nAttr. frac. ex.           0.06    -0.14     0.22\nAttr. frac. pop           0.04       NA       NA\nchi2(1)                   0.35       NA       NA\nPr&gt;chi2                  0.553       NA       NA\n\n\nCode\nCS(copdata, \"case\", \"eggplant\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     123        93   216 0.57\nUnexposed    83        60   143 0.58\nTotal       206       153   359 0.57\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference          -0.01    -0.12     0.09\nRisk ratio                0.98     0.82     1.18\nPrev. frac. ex.           0.02    -0.18     0.18\nPrev. frac. pop           0.01       NA       NA\nchi2(1)                   0.04       NA       NA\nPr&gt;chi2                  0.837       NA       NA\n\n\nCode\nCS(copdata, \"case\", \"moussaka\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     201       137   338 0.59\nUnexposed    14        22    36 0.39\nTotal       215       159   374 0.57\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference           0.21     0.04     0.37\nRisk ratio                1.53     1.01     2.32\nAttr. frac. ex.           0.35     0.01     0.57\nAttr. frac. pop           0.32       NA       NA\nchi2(1)                   5.64       NA       NA\nPr&gt;chi2                  0.018       NA       NA\n\n\n\n\nCode\n# You can save time (and probably typos!) by creating a vector for food variables...\nfood_vars &lt;- c(\"feta\", \"sardines\", \"eggplant\", \"moussaka\", \n               \"orzo\", \"greeksal\", \"dessert\", \"bread\",  \n               \"champagne\", \"beer\", \"redwine\", \"whitewine\")\n\n# ...and using EpiStats::CSTable() to run all variables together!\nCSTable(copdata, \"case\", food_vars)\n\n\n$df\n          Tot.Exp Cases.Exp AR.Exp% Tot.Unexp Cases.Unexp AR.Unexp%   RR CI.ll\norzo          338       202   59.76        36          13     36.11 1.65  1.06\nmoussaka      338       201   59.47        36          14     38.89 1.53  1.01\nchampagne     316       187   59.18        48          21     43.75 1.35  0.97\ngreeksal      211       114   54.03       154          95     61.69 0.88  0.73\ndessert       149        90   60.40       198         106     53.54 1.13  0.94\nbeer          281       166   59.07        78          41     52.56 1.12  0.89\nredwine        80        42   52.50       259         150     57.92 0.91  0.72\nsardines      255       150   58.82       117          65     55.56 1.06  0.87\nwhitewine     260       150   57.69        98          54     55.10 1.05  0.85\nbread         342       196   57.31        29          16     55.17 1.04  0.74\nfeta          271       156   57.56       102          60     58.82 0.98  0.81\neggplant      216       123   56.94       143          83     58.04 0.98  0.82\n          CI.ul p(Chi2)\norzo       2.58   0.006\nmoussaka   2.32   0.018\nchampagne  1.89   0.044\ngreeksal   1.04   0.144\ndessert    1.36   0.202\nbeer       1.42   0.303\nredwine    1.14   0.393\nsardines   1.28   0.553\nwhitewine  1.29   0.659\nbread      1.46   0.823\nfeta       1.19   0.826\neggplant   1.18   0.837\n\n\n\n\nb) Prepare the RR table for publication\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse flextable() and set_header_labels().\n\n\n\n\n\nCode\nrr_tbl &lt;- CSTable(copdata, \"case\", food_vars) %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column() %&gt;% \n  flextable() %&gt;% \n   set_header_labels(\n     values = c(\"Food Item\",\n                \"Total exposed\",     \n               \"Cases exposed\", \n               \"AR among exposed\",    \n               \"Total unexposed\",\n               \"Cases unexposed\",\n               \"AR among unexposed\",\n               \"RR\",         \n               \"95% lower CI\",             \n               \"95% upper CI\",\n               \"p-value\"))\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\n· What can you infer from this table?\n· Considering the relative risks, which food or drink items do you think were most likely to be the vehicle(s) of infection in this outbreak?\n· Do you think there are any confounders or effect modifiers? If so, how would you investigate these further?\n\n\n\nThe interesting results here are that the food items that are most suspicious are orzo, moussaka and champagne. Orzo as such is unlikely to be contaminated, but as you can see in the picture (and from the dinner night), it was served with pesto! Maybe it was the pesto? Who-ho-ho!\nBefore one jumps into conclusions, consider that this result could be due to confounding! Maybe orzo was \"clean\" but eaten by all the people who ate the food item that actually was contaminated!(Optional)"
  },
  {
    "objectID": "SimOb_RInject14.html#dose-response",
    "href": "SimOb_RInject14.html#dose-response",
    "title": "Inject 14: Univariable analysis",
    "section": "5. Dose Response",
    "text": "5. Dose Response\n\na) Orzo\n\n\nCode\n# Binomial regression for RRs. \n# The outcome needs to be exponentiated so we can interpret it properly!\nbinom_orzoD &lt;- glm(case ~ orzoD, data = copdata, \n             family = binomial(link = \"log\"))\n\n# To get exponentiated:\nbinom_orzoD_exp &lt;- glm(case ~ orzoD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_orzoD_exp\n\n\n\n\n  \n\n\n\n\n\nb) Moussaka\n\n\nCode\n# Let's get the results directly exponentiated\nbinom_moussakaD_exp &lt;- glm(case ~ moussakaD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_moussakaD_exp\n\n\n\n\n  \n\n\n\n\n\nc) Champagne\n\n\nCode\n# Let's get the results directly exponentiated\nbinom_champagneD_exp &lt;- glm(case ~ champagneD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_champagneD_exp"
  },
  {
    "objectID": "SimOb_RInject10.html#learning-outcomes",
    "href": "SimOb_RInject10.html#learning-outcomes",
    "title": "Case Definition",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nApply case definition criteria to a dataset using logical arguments in R"
  },
  {
    "objectID": "SimOb_RInject10.html#storyplot-description",
    "href": "SimOb_RInject10.html#storyplot-description",
    "title": "Case Definition",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nYou will now create a new column in the data set to hold the case definition you decided in a previous step during your investigation. You can call this column case and set it to TRUE if the individual meets the case definition criteria and FALSE if not. You will use this column later on for any calculations needed (descriptive statistics, two-by-two tables to compute measures of association, etc.) to figure out the culprit of this outbreak."
  },
  {
    "objectID": "SimOb_RInject10.html#questionsassignments",
    "href": "SimOb_RInject10.html#questionsassignments",
    "title": "Case Definition",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments\nIf you closed your R project, please open it again and load the clean dataset. We strongly recommend you use the Copenhagen_clean1_2024.rds provided by us in EVA. This is just to be sure all needed changes in that file for the code to work have been done (as you may have changed the file in a slightly different way than we have).\nTo be sure we all start from the same case definition, let’s agree that a case was defined as a person who:\n\nattended the school dinner on 11 November 2006 (i.e. is on the linelist)\nate a meal at the school dinner (i.e. was exposed)\nfell ill after the start of the meal\nfell ill within the time period of interest after the school dinner\nsuffered from diarrhoea with or without blood, or vomiting\n\nNon cases (not-ill) were defined as people who:\n\nattended the school dinner on 11 November 2006 (i.e. are on the linelist)\nate a meal at the school dinner (i.e. were exposed)\ndid not fall ill within the time period of interest\ndid not develop diarrhoea (with or without blood) or vomiting"
  },
  {
    "objectID": "SimOb_RInject10.html#install-packages-if-needed-and-load-libraries",
    "href": "SimOb_RInject10.html#install-packages-if-needed-and-load-libraries",
    "title": "Case Definition",
    "section": "3.1 Install packages (if needed) and load libraries",
    "text": "3.1 Install packages (if needed) and load libraries\n\n\nCode\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "SimOb_RInject10.html#identify-the-variables-you-need-to-apply-the-case-definition-criteria.",
    "href": "SimOb_RInject10.html#identify-the-variables-you-need-to-apply-the-case-definition-criteria.",
    "title": "Case Definition",
    "section": "3.3 Identify the variables you need to apply the case definition criteria.",
    "text": "3.3 Identify the variables you need to apply the case definition criteria.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nThe variables we need from the dataset to apply the above case definition are: meal, onset_datetime, diarrhoea, bloody and vomiting."
  },
  {
    "objectID": "SimOb_RInject10.html#create-a-new-case-column-to-hold-the-binary-case-definition-variable.-lets-think-about-how-to-do-this-little-by-little",
    "href": "SimOb_RInject10.html#create-a-new-case-column-to-hold-the-binary-case-definition-variable.-lets-think-about-how-to-do-this-little-by-little",
    "title": "Case Definition",
    "section": "3.4 Create a new case column to hold the binary case definition variable. Let’s think about how to do this little by little:",
    "text": "3.4 Create a new case column to hold the binary case definition variable. Let’s think about how to do this little by little:\n\na) Ate a meal at the school dinner\nYou decide to exclude any people from the cohort who didn’t eat at the dinner, because we specifically hypothesised a food item to be the vehicle of infection in this outbreak. Thus, filter your dataset to those who ate a meal: Keep in your dataset only those who ate a meal.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nfilter by those with meal == TRUE.\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat are some of the implications this decision may lead to? (excluding any people from the cohort who didn’t eat at the dinner)\n\n\n\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  filter(meal == TRUE)\n\n\n\n\n\n\n\n\nOnce you’ve thought about the above, have a look here\n\n\n\n\n\nSeven of the respondents actually said they did not eat the meal, but when it came to the questions about which food items they ate, they provided answers! This issue could have been minimised by:\n- At the survey state, one could adjust the design of an electronic questionnaire to prevent key questions from being skipped. This can come with both pros and cons. Allow fellows to discuss if time allows.\n- Explore your data further, realise this is the case, and recode the meal variable for these individuals as TRUE. =&gt; This would be the way to go, but is not what we did in our example because we tried to keep it simple, and also because it is good to show that you may not always clean the data perfectly, and that has consequences: You can highlight the importance or really explore your data in depth.\nBy making the above decision, we may be missing cases and non-cases people, and thus, modifying the final estimate of our measure of association. =&gt; It is very important to know your data, explore it deeply and try to clean it as well as possible. Every step one makes when cleaning the data may have a consequence, and we should be aware of it when making the data cleaning decisions and when interpreting the results.\n\n\n\n\n\nb) Fell ill after the start of the meal\nWe define “fell ill” as any person having had diarrhoea with OR without blood, OR vomiting. To capture this information easily, you will create a new gastrosymptoms variable. This variable will indicate that the person had one OR (“or” is R is achieved by using |) more of the clinical symptoms in your definition.\nNote that we the concept of having eaten a meal is already included as per one of the steps above.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nCreate a new gastrosymptoms column in your line list with mutate() and case_when().\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat are some of the implications this decision may lead to? (defining “fell ill” as any person who reported having diarrhoea with OR without blood, OR vomiting)\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above, have a look here\n\n\n\n\n\nHaving one clinical symptom enough to be considered a potential case at this point may be considered too unspecific (low specificity). For example, a person who ate at the dinner party and developed diarrhoea for other reasons other than food poisoning (say, they recently started on antibiotics known for unbalancing the intestinal flora and causing diarrhoea) could be misclassified as a potential case. (Note we talk about potential case, and not case; that is because here we are not talking about cases per-se yet, but this decision has implications for when applying the case definition below).\nMoreover, those who did not report clinical symptoms will be defined as non-cases. Thus, we are assuming that these individuals did not develop symptoms because they didn’t report them. The missing values could be due to, for example, them skipping the questions in the questionnaire. Some individuals may be reluctant to report symptoms, due to shame, fear of repercussion, or others. It is important to think ahead, before the interview, about ways to minimise these situations. For example, through questionnaire design, you may impede skipping questions; you could promote trust by using the right interviewers (in some cases this will be someone from the community, in others someone form specific NGOs, someone of a specific race or gender, etc); choose to carry out online questionnaires vs in person (or vice versa, depending on the situation), etc.\n\n\n\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  mutate(gastrosymptoms = case_when(\n    # Those had diarrhoea...\n    diarrhoea == TRUE |\n      #or bloody diarrhoea...\n    bloody == TRUE |\n      # or vomiting, are marked as TRUE (fell ill after the meal)\n    vomiting == TRUE ~ TRUE,\n    # The rest are FALSE. This includes those who ate a meal but had no symptoms (did not fell ill after the meal)\n    .default = FALSE)\n    )\n\n\n\n\nc) Fell ill within the time period of interest\n\nHmmm… what is the time period of interest? You could start calculating the incubation period, which can be defined by calculating the time between exposure (the meal) and onset of symptoms, and then looking at the distribution of these time differences. In this outbreak, incubation periods are easy to calculate, because everyone was exposed at (roughly) the same time and on the same day (eating the meal at the school dinner party).\nDinner was served at 18:00 roughly for everyone. Create a new meal_datetime variable with this information for all people in your dataset (as per 05 Oct 2024, at 18:00h).\n\n\n\nCode\n# Start with copdata:\ncopdata &lt;- copdata %&gt;% \n  # Create new column for meal date and time:\n  mutate(meal_datetime = lubridate::ymd_hm(\"2024-10-05 18:00\"))\n\n\n\nYou can calculate the incubation period for each participant by subtracting onset_datetime - meal_datetime.\nThen, take the median() of that column to calculate a median incubation period, this will help you start having some hypothesis about the type of pathogen we are dealing with until the lab results come back.\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nBe aware of the type of variable incubation is (check class()), as well as of missing valuesNA.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe incubation period of a disease is the time from an exposure resulting in infection until the onset of disease. Because infection usually occurs immediately after exposure, the incubation period is generally the duration of the period from the onset of infection to the onset of disease – Rothman, Greenland, Lash (2017): Modern Epidemiology, 3rd edition\n\n\n\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  mutate(incubation = onset_datetime - meal_datetime,\n         incubation = as.numeric (incubation))\n\n\nmedian(as.numeric(copdata$incubation), na.rm = TRUE)\n\n\n[1] 15\n\n\n\n\n\n\n\n\nNow we are messing up with your brain…\n\n\n\n\n\nIf you pay attention, there were two individuals who don’t have a time recorded, only a date, the day of the dinner. These people probably got sick the same night they had the dinner, but the exact time was not recoded. They way we’ve managed the data will insert “00:00” in a missing value of a time. This means that the 2 people that got sick the day of the dinner have been recorded sick before the dinner (in the early morning of the day of the dinner). The two people have a negative incubation period! This should not happen. If you feel the force is with you, you can modify this and fix the error (if you do this, your results will be a bit different than your colleagues, but similar). We will continue with this “erroneous” data, for easiness. But note that in real life, as soon as you realise there is a coding error like this, you would have to go back to your cleaning code and fix the error! This may happen a couple of times during your outbreak investigation, and is totally normal. Cleaning data is not an easy job!\n\n\n\nWe see that the median incubation time is 15 hours. This is useful information, as incubation periods tend to be relatively pathogen-specific.\nBased on this, say you define and limit the maximum incubation period to 48 hours after the meal, as the data points to a fast-acting bacterial toxin or a virus. That is, dinner participants should have developed (onset_datetime) at least one symptom (diarrhoea, bloody or vomiting) 48h after meal_datetime to become a case.\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat are some of the implications this decision may lead to? (implications of this case definition)\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above, have a look here\n\n\n\n\n\nAll those not developing at least one symptom (diarrhoea with OR without blood, OR vomiting) 48h after the dinner are considered non-cases. This could (depending on how you decide to analyse your data) include those who had no symptoms at all, those who have missing data on the onset_datetime variable, and/or those who had symptoms before eating the meal. This is a reminder that you need to be both careful and aware of the implications of your data analysis decisions. If a person had clinical symptoms before eating the meal, they are considered as not-cases. However, it could be that a person had symptoms before the meal, and yet, still got infected by the pathogen when eating their meal (bad luck, we know…). According to this definition, we would be missing that case.\n\n\n\n\n\nd) Finally, with this information you can create a new case column to hold the binary (TRUE/FALSE) case definition variable.\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  mutate(case = case_when(\n    # Those who had symptoms &lt;48h from the meal are cases (TRUE)\n    gastrosymptoms == TRUE & \n      onset_datetime &gt;= meal_datetime &\n      onset_datetime &lt;= (meal_datetime + days(2)) ~ TRUE,\n    # Those who had symptoms &gt;48h from the meal are non-cases (FALSE)\n    gastrosymptoms == TRUE & \n      onset_datetime &gt; (meal_datetime + days(2)) ~ FALSE,\n    # The rest are considered non-cases. Including, those who had no symptoms at all, who have missing data on the onset_datetime variable, or who had symptoms before eating the meal \n    .default = FALSE)\n  )\n\n\nNote that we may be incurring in misclassification bias with the code above. The last section indicates that if a person had clinical symptoms before eating the meal, they are considered as non-cases. However, it could be that a person had symptoms before the meal, and yet, still got infected by the pathogen when eating their meal (bad luck, we know…).\nMoreover, if you remember, there were a couple of people with an dayonset, but no starthour. The code we used (lubridate::ymd_h with argument truncated = 2) results in dates with missing starthour being converted to date-time, with the missing time being set to 00:00 (midnight). This means that these two people don’t fulfill the case definition criteria because we marked their symptoms started early in the morning of Nov 11 (at 00:00), before the meal time (18:00), and thus, they did not “fell ill within the time period of interest”.\nThe two situations above are a reminder that you need to be both careful and aware of the implications of your data analysis decisions.\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do you think are the risks of mis-classifying cases as non-cases in your analysis?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above, have a look here\n\n\n\n\n\nWe will have bias either towards or away from the null, depending on the proportions of subjects misclassified.\n\n\n\n\n\nCode\n# Tabulate cases:\njanitor::tabyl(dat = copdata, case)\n\n\n\n\n  \n\n\n\nLet’s have a look at how many people ate a meal, had symptoms, and were considered as cases after applying our case definition:\n\n\nCode\ncopdata %&gt;% \n  summarise(atemeal = sum(meal == TRUE),\n            hadsympt = sum(gastrosymptoms == TRUE),\n            nb_cases = sum(case == TRUE)\n            )"
  },
  {
    "objectID": "SimOb_RInject11.html#learning-outcomes",
    "href": "SimOb_RInject11.html#learning-outcomes",
    "title": "Laboratory data and descriptive analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nMerge two datasets using a common column.\nDiscuss which descriptive statistics would you use to describe the cases\nDescribe the cases by person and place (this is an outbreak in a high school, so we won’t explore “place” this time!)\nGenerate preliminary hypotheses bases on the descriptions."
  },
  {
    "objectID": "SimOb_RInject11.html#storyplot-description",
    "href": "SimOb_RInject11.html#storyplot-description",
    "title": "Laboratory data and descriptive analysis",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nYou received data from the laboratory regarding [WE NEED LAB DATA AND DECISIONS ON WHAT TO ADD HERE]. You will have to merge the questionnaire data with the data coming from the laboratory.\nNow that your dataset is clean and the lab data merged, it is time to describe the people identified as cases so far and generate a hypothesis to inform the next steps in the outbreak investigation. Note that you should try to have a data analysis plan before any data collection. Nevertheless, during the urgency of outbreak investigations, questionnaire development may sometimes occur before you had time to draft a proper analysis plan (as it is the case in this simulated outbreak). Drawing “dummy” tables and graphs will help you precise the type of statistics you will carry out later on."
  },
  {
    "objectID": "SimOb_RInject11.html#questionsassignments",
    "href": "SimOb_RInject11.html#questionsassignments",
    "title": "Laboratory data and descriptive analysis",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments\nIf you closed your R project, please open it again and load the clean dataset. We recommend you use the Copenhagen_clean2_2024.rds provided by us in EVA. This is just to be sure all needed changes in that file for the code to work have been done (as you may have changed the file in a slightly different way than we have)."
  },
  {
    "objectID": "SimOb_RInject11.html#install-packages-if-needed-and-load-libraries",
    "href": "SimOb_RInject11.html#install-packages-if-needed-and-load-libraries",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.1 Install packages (if needed) and load libraries",
    "text": "3.1 Install packages (if needed) and load libraries\n\n\nCode\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "SimOb_RInject11.html#describe-the-outbreak-in-terms-of-time.",
    "href": "SimOb_RInject11.html#describe-the-outbreak-in-terms-of-time.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.4 Describe the outbreak in terms of time.",
    "text": "3.4 Describe the outbreak in terms of time.\nYou could use ggplot2.To learn more about ggplot2 you can check The Epidemiologist R Handbook: Chapter on ggplot and ggplot2 - Elegant Graphics for Data Analysis.\n\na) Create a histogram to visualize the incubation period (geom_histogram is a good function to use for this!).\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat can you infer from the incubation periods in the histogram?\n\n\n\n\n\nCode\n#| label: inc_time\n\n# Create a dataset with only cases\ncases &lt;- copdata %&gt;% \n  filter(case == TRUE)\n\nincplot &lt;- cases %&gt;% \n  # Create an empty ggplot frame:\n  ggplot() +\n  # Add a histogram of incubation:\n  geom_histogram(\n    mapping = aes(x = incubation), \n    # Set bin widths to 6 hours:\n    binwidth = 6) +\n  # Adapt scale to better fit data\n  scale_x_continuous(breaks = seq(0, 48, 6)) + \n  # Label x and y axes:\n  labs(x = \"Incubation period in 6-hour bins\",\n       y = \"Number of cases\")\n\n# Print plot:\nincplot\n\n\n\n\n\n\n\nb) Create an epicurve for the date and time of onset (using onset_datetime), limiting the input data to cases.\n\nUse scale_x_datetime() and chose a value for date_breaks() based on your calculated incubation period.\nLabel your x and y axes using labs().\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nA rule of thumb is to use one third or one fourth of the average incubation period as an interval. For our investigation this means we should use approximately a 6h interval for the date_breaks argument.\n\n\n\n\n\nCode\n# Create a vector with sequences every 6h from the first to the last case\nbreaks_6h &lt;- seq(from = min(cases$onset_datetime, na.rm = TRUE),\n                 to = max(cases$onset_datetime, na.rm = TRUE),\n                 by = \"6 hours\")\n\n# Fetch cases data:\nepicurve_datetime &lt;- cases %&gt;%  \n  # Add factor onset_datetime to ggplot aesthetic:\n  ggplot(\n    mapping = aes(x = onset_datetime)) + \n  # Add geom_histogram:\n  geom_histogram(\n    # Apply the vector of requences created above\n    breaks = breaks_6h) +\n  # Adapt scale to data and adjust axis label angle:\n  scale_x_datetime(\n    date_breaks = \"6 hours\",\n    labels = label_date_short()) +\n  # Update x and y axis labels:\n  labs(x = \"Date and time of onset symptoms\", \n       y = \"Number of cases\") +\n  # Remove unnecessary grid lines:\n  theme_bw()\n\n# Print epicurve:\nepicurve_datetime\n\n\n\n\n\n\nBuilding up on your previous epicurve, create another epicurve to compare between sexes and additionally investigate how teachers versus students were distributed.\n\n\nUse fill = group\nUse sex as your facets for facet_wrap()\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nfill adds an additional variable to be displayed in the plot: group is going to determine the fill-colour of our bars. facet_wrap splits the graph in two: one each for the two levels of sex.\n\n\n\n\n\n\n\n\n\nDo you feel like a challenge?\n\n\n\n\n\nIf you want, try using str_glue() to add the total number of cases to the sub-title of the plot. str_glue() is a very useful function that allows you to dynamically create a summary statistic from your data within some normal text.\n\n\n\n\n\nCode\nepicurve_strata &lt;- cases %&gt;% \n  # Add factor onset_day to ggplot aesthetic:\n  ggplot(\n    mapping = aes(x = onset_datetime, fill = group)) + \n  # Add nicer fill colours:\n  scale_fill_manual(values = c(\"darkred\", \"lightblue\")) +\n    # Add geom_histogram:\n  geom_histogram(\n    # Apply the vector of requences created above\n    breaks = breaks_6h) +\n  # Adjust x axis scales to a suitable unit:\n  scale_x_datetime(\n    date_breaks = \"6 hours\", \n    labels = label_date_short()) +\n  # Update x and y axis labels:\n  labs(x = \"Date and time of onset\", \n       y = \"Number of cases\", \n       fill = \"Group\", \n       title = \"Epicurve of the outbreak, stratified by sex\",\n       subtitle = str_glue(\"Spetses, October 2024, N = {sum(copdata$case)}\")) +\n  # Stratify by sex:\n  facet_wrap(facets = \"sex\",\n             ncol = 2) +\n  # Add theme:\n  theme_bw()\n\n# Print epicurve:\nepicurve_strata \n\n\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat does the stratified epicurve tell you? Does the shape of the epicurve support a viral or toxic aetiology? What other information can you obtain from it?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above questions, have a look here\n\n\n\n\n\nWhen constructing an epicurve, we need to decide on the resolution, i.e. the time interval for a single bar. A rule of thumb is to use one third or one fourth of the average incubation period as an interval. For our investigation this means we should use approximately a 6h interval.\nThis seems a good choice, as we saw that the daily interval was too coarse to really see the signal we are after. The epicurve and the summary of the incubation period show that there seemed to be a rapid onset of symptoms following exposure. This is in line with our previous suspicion that a virus or a toxin might be the causative agent in the outbreak.\nThe unimodal shape with the sharp peak suggests a point source, while the tail on the right-hand side could be explained by secondary cases or background noise. Also, people that only consumed a little contaminated food and therefore only a low infectious dose could have a longer incubation period and could explain the late cases.\nThe above results are in line with norovirus as the prime suspect, but the symptoms are not a textbook fit. There are too few people that experienced vomiting! Looking forward to receiving the lab results!"
  },
  {
    "objectID": "SimOb_RInject11.html#describe-the-outbreak-in-terms-of-person.",
    "href": "SimOb_RInject11.html#describe-the-outbreak-in-terms-of-person.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.5. Describe the outbreak in terms of person.",
    "text": "3.5. Describe the outbreak in terms of person.\nYou could use tabyl(). For more detail on the tabyl() function and the adorn_XYZ helpers, see the janitor documentation or The Epidemiologist R Handbook section on tabulation.\n\na) Create a cross-tabulation of case with group.\n\n\nCode\ncopdata %&gt;% \n  janitor::tabyl(case, group) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() \n\n\n\n\n  \n\n\n\n\n\nb) Create a cross-tabulation of case with sex.\n\n\nCode\ncopdata %&gt;% \n  janitor::tabyl(case, sex) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do you think of these results?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above questions, have a look here\n\n\n\n\n\nThe distribution of the cohort regarding sex, group and class also didn’t reveal anything unusual. Students seem a bit more affected by the outbreak than teachers and the attack rate is higher for older students in higher classes. This, however, is a purely descriptive result.\n\n\n\n\n\n\n\n\n\nDo you feel like a challenge?\n\n\n\n\n\nIf you want, create an age-sex pyramid using the apyramid package. To do so, first create an age category variable with the epkit function age_categories().\n\n\n\n\n\nc) Extra - Age-sex pyramid of cases.\nHint: Change show_midpoint = FALSE to TRUE to see skewedness in the data patterns more easily.\n\n\nCode\ncopdata &lt;- copdata %&gt;% \n  # Create age categories:\n  mutate(age_cat = epikit::age_categories(\n    # Name of age column:\n    x = age, \n    # Define the age categories:\n    breakers = c(0, 10, 16, 18, 20, 50, 70)\n    )\n  )\n\n\n# Check age categories:\njanitor::tabyl(copdata, age_cat)\n\n\n\n\n  \n\n\n\nCode\n# Pipe copdata:\nagesex &lt;- copdata %&gt;% \n  # Filter for cases only:\n  filter(case == TRUE) %&gt;% \n  # Create age sex pyramid:\n  apyramid::age_pyramid(\n  # Specify column containing age categories:\n    age_group = \"age_cat\",\n    # Specify column containing sex:\n    split_by = \"sex\", \n    # Don't show midpoint on the graph:\n    show_midpoint = FALSE\n    )\n\n# Print plot:\nagesex"
  },
  {
    "objectID": "SimOb_RInject11.html#explore-the-distribution-of-all-clinical-signs-symptoms.",
    "href": "SimOb_RInject11.html#explore-the-distribution-of-all-clinical-signs-symptoms.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.6 Explore the distribution of all clinical signs (symptoms).",
    "text": "3.6 Explore the distribution of all clinical signs (symptoms).\n\na) Create a summary table with symptoms stratified by case definition, and present an overall column as well. You could use tabyl() or gtsummary::tbl_summary(). You can find further information about gtsummary in The Epidemiologist R handbook section on gtsummary.\n\n\nCode\n# Create summary table:\ntabsymptoms &lt;- copdata %&gt;% \n    # Select person characteristics to summarise:\n  select(case, diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain) %&gt;% \n  # transform clinical symptoms to factors, so NA can be accounted properly in the table\n  dplyr::mutate(\n    across(.cols = c(diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain), \n           .fns = ~as.factor(.))) %&gt;%\n  # Make NA a explicit level of factor variables\n  dplyr::mutate(\n    across(.cols = c(diarrhoea, bloody, vomiting,\n           abdo, nausea, fever,headache, jointpain),\n           .fns = ~forcats::fct_na_value_to_level(.))) %&gt;% \n    \n  # Create the summary table:\n  gtsummary::tbl_summary(\n    # Stratify by case:\n    by = case, \n    # Calculate row percentages:\n    percent = \"column\",\n    # Create nice labels:\n    label  = list(\n      diarrhoea   ~ \"Diarrhoea\",                           \n      bloody      ~ \"Dysentary\",\n      vomiting    ~ \"Vomiting\",\n      abdo        ~ \"Abdominal pain\",\n      nausea      ~ \"Nausea\", \n      fever       ~ \"Fever\", \n      headache    ~ \"Headache\", \n      jointpain   ~ \"Joint pain\")\n    \n  ) %&gt;% \n  \n  # Add totals:\n  add_overall() %&gt;% \n  # Make variable names bold and italics:\n  bold_labels() %&gt;% \n  italicize_labels() %&gt;% \n  # Modify header:\n  modify_header(\n    label = \"**Characteristic**\",\n    stat_0 = \"**Overall**\\n **N** = {N}\",\n    stat_1 = \"**Non-case**\\n **N** = {n}\",\n    stat_2 = \"**Case**\\n **N** = {n}\", \n    )\n\n# Print the table:\ntabsymptoms\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Overall\nN = 3771\n      Non-case\nN = 1611\n      Case\nN = 2161\n    \n  \n  \n    Diarrhoea\n\n\n\n        FALSE\n46 (18%)\n40 (100%)\n6 (2.8%)\n        TRUE\n206 (82%)\n0 (0%)\n206 (97%)\n    Dysentary\n\n\n\n        FALSE\n189 (97%)\n42 (100%)\n147 (97%)\n        TRUE\n5 (2.6%)\n0 (0%)\n5 (3.3%)\n    Vomiting\n\n\n\n        FALSE\n149 (69%)\n42 (100%)\n107 (62%)\n        TRUE\n66 (31%)\n0 (0%)\n66 (38%)\n    Abdominal pain\n\n\n\n        FALSE\n35 (14%)\n6 (12%)\n29 (15%)\n        TRUE\n207 (86%)\n44 (88%)\n163 (85%)\n    Nausea\n\n\n\n        FALSE\n55 (25%)\n12 (26%)\n43 (24%)\n        TRUE\n169 (75%)\n34 (74%)\n135 (76%)\n    Fever\n\n\n\n        FALSE\n127 (74%)\n32 (80%)\n95 (73%)\n        TRUE\n44 (26%)\n8 (20%)\n36 (27%)\n    Headache\n\n\n\n        FALSE\n83 (38%)\n11 (25%)\n72 (41%)\n        TRUE\n137 (62%)\n33 (75%)\n104 (59%)\n    Joint pain\n\n\n\n        FALSE\n159 (85%)\n32 (84%)\n127 (85%)\n        TRUE\n29 (15%)\n6 (16%)\n23 (15%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nDo you think the symptoms selected for the case definition were the right ones, or would you change anything?\n\n\n\n\n\n\n\n\n\nDo you feel like a challenge?\n\n\n\n\n\nIf you want, present the symptoms in an ordered bar chart. To do so, reshape the data using pivot_longer(), and then group_by(), summarise() and count() to tally up the counts for each symptom, stratified by case definition. Use ggplot2::coord_flip() for a better visualisation.\n\n\n\n\n\nb) Extra - Bar plot of symptoms stratified by case definition.\n\n\nCode\n# Create list of symptom variables:\nsymptoms &lt;- c(\"diarrhoea\", \n              \"bloody\", \n              \"vomiting\", \n              \"abdo\", \n              \"nausea\", \n              \"fever\", \n              \"headache\", \n              \"jointpain\")\n\n# Create nice labels for case definition:\ncaselabs &lt;- ggplot2::as_labeller(c(`FALSE` = \"Non-case\", \n                                   `TRUE` = \"Case\"))\n# Select variables and cases:\nsymptom_bar &lt;- copdata %&gt;% \n  # Select symptom columns:\n  select(case, c(all_of(symptoms))) %&gt;%\n  # Drop NAs:\n  drop_na() %&gt;% \n  # Reshape (pivot longer):\n  pivot_longer(!case, \n               names_to = \"Symptoms\", \n               values_drop_na = TRUE) %&gt;% \n  # Keep only TRUE values:\n  filter(value == TRUE) %&gt;% \n \n   # Group by symptoms and case:\n  group_by(Symptoms, case) %&gt;% \n  # Count for each symptom by case:\n  dplyr::summarise(count = n()) %&gt;% \n  # Create plot:\n  ggplot(\n    mapping = aes(\n    # Order symptom bars so most common ones are ontop:\n    x = reorder(Symptoms, desc(count), decreasing = TRUE), \n    y = count)) +\n  # Display bars as proportions\n  geom_bar(stat = \"identity\") +\n  # Update x axis label:\n  xlab(\"Symptoms\") +\n  # Update y axis label:\n  ylab(\"Proportion of respondents\") +\n  # Flip plot on its side so symptom labels are clear:\n  coord_flip() +\n  # Facet the plot by (labelled) case:\n  facet_wrap(facets = \"case\",\n             labeller = caselabs,\n             ncol = 2)\n\n\n`summarise()` has grouped output by 'Symptoms'. You can override using the\n`.groups` argument.\n\n\nCode\n# Print plot:\nsymptom_bar"
  },
  {
    "objectID": "SimOb_RInject11.html#draft-the-relevant-paragraphs-and-tables-andor-figures-in-your-outbreak-report-methods-and-results.",
    "href": "SimOb_RInject11.html#draft-the-relevant-paragraphs-and-tables-andor-figures-in-your-outbreak-report-methods-and-results.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.8 Draft the relevant paragraph(s) and table(s) and/or figure(s) in your outbreak report (Methods and results).",
    "text": "3.8 Draft the relevant paragraph(s) and table(s) and/or figure(s) in your outbreak report (Methods and results).\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nTo save your tabyl table as a .docx, you could convert your tabyl to flextable (as_flex_table()), ensure only one line per row (flextable::autofit()) and save as .docx (flextable::save_as_docx(path = \"nameoftable.docx\")"
  },
  {
    "objectID": "SimOb_RInject11.html#merge-and-explore-the-lab-data",
    "href": "SimOb_RInject11.html#merge-and-explore-the-lab-data",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.3 Merge and explore the lab data",
    "text": "3.3 Merge and explore the lab data\n\n\nCode\ncopdatalab &lt;- left_join(copdata, lab, by = \"id\")\n# Tabulate:\njanitor::tabyl(dat = copdatalab, result)"
  },
  {
    "objectID": "SimOb_RInject14.html#learning-outcomes",
    "href": "SimOb_RInject14.html#learning-outcomes",
    "title": "Univariable analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nPerform hypothesis tests.\nEstimate risk ratios (also called relative risk) for categorical data.\nInterpret the univariable results.\n(Optional) Investigate dose-response relationships in categorical data.2. Story/plot description"
  },
  {
    "objectID": "SimOb_RInject14.html#storyplot-description",
    "href": "SimOb_RInject14.html#storyplot-description",
    "title": "Univariable analysis",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nYou have just estimated risk ratios (RR) of individual food items manually to better understand the concept. RR give you an idea of which food items could be the culprit(s) of the outbreak.\nNow, you will practice performing hypothesis testing and calculating RR in R to investigate the associations of suspicious food items with the disease.\nNote that, although this is not an exhaustive list of tests, the following can be useful for this exercise (relevant for comparisons between two groups):\n\nFor continuous variables:\n\nshapiro.test() (for checking if normally distributed)\nt.test() (for normal distributions)\nwilcox.test() (for non-parametric testing. Used to determine if two numeric samples are from the same distribution, when their populations are not normally distributed or have unequal variance.)\n\nFor categorical variables:\n\nchisq.test() (if all comparisons include at least 5 cases)\nfisher.test() (if there are &lt; 5 cases for any comparison)"
  },
  {
    "objectID": "SimOb_RInject14.html#questionsassignments",
    "href": "SimOb_RInject14.html#questionsassignments",
    "title": "Univariable analysis",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments"
  },
  {
    "objectID": "SimOb_RInject14.html#optional-dose-response",
    "href": "SimOb_RInject14.html#optional-dose-response",
    "title": "Univariable analysis",
    "section": "3.5. (Optional) Dose Response",
    "text": "3.5. (Optional) Dose Response\nCheck for a dose-response relationship between the food items with the highest RR values (the top 3) and being a case.\n\na) Orzo\n\n\nCode\n# Binomial regression for RRs. \n# The outcome needs to be exponentiated so we can interpret it properly!\nbinom_orzoD &lt;- glm(case ~ orzoD, data = copdata, \n             family = binomial(link = \"log\"))\n\n# To get exponentiated:\nbinom_orzoD_exp &lt;- glm(case ~ orzoD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_orzoD_exp\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do these results tell you?\n\n\n\nResults suggest a dose response relationship of having eaten orzo, pointing towards orzoas the potential vehicle. The higher the amount of orzothey ate, the stronger is the association (RR) with getting ill/being a case.\n\n\nb) Moussaka\n\n\nCode\n# Let's get the results directly exponentiated\nbinom_moussakaD_exp &lt;- glm(case ~ moussakaD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_moussakaD_exp\n\n\n\n\n  \n\n\n\n\n\nc) Champagne\n\n\nCode\n# Let's get the results directly exponentiated\nbinom_champagneD_exp &lt;- glm(case ~ champagneD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_champagneD_exp"
  },
  {
    "objectID": "SimOb_RInject14.html#summary",
    "href": "SimOb_RInject14.html#summary",
    "title": "Univariable analysis",
    "section": "3.6 Summary",
    "text": "3.6 Summary\nAs a summary of what you've done above, answer these questions:\n\nIs the respondents' sex associated with being a case?\nIs the school class associated with being a case?\nWhich foods increase the risk of being a case?\n(Optional) Is there a dose-response relationship between the food items and being a case?\nWhat do you think is the most likely culprit(s) of this outbreak at this point? Are there any risk factors you would like to highlight?"
  },
  {
    "objectID": "SimOb_RInject15.html#learning-outcomes",
    "href": "SimOb_RInject15.html#learning-outcomes",
    "title": "Stratified analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nConsider the effect of confounding and effect modification on the association between exposure and disease,\nPerform stratified analysis using the Mantel-Haenszel approach\n\nThe use of stratified analysis, is the first step to identify confounding factors and effect modifiers one by one (after, of course, thinking which variables could potentially be confounders or effect modifiers). As the final step, you will be using Regression Models to account for confounding and check for effect modification. We will see these with you in the Multivariable Module (MVA), next year."
  },
  {
    "objectID": "SimOb_RInject15.html#storyplot-description",
    "href": "SimOb_RInject15.html#storyplot-description",
    "title": "Stratified analysis",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nFrom the univariable analysis, it seems that eating orzpo and eating moussaka as well as drinking champagne are associated with the highest risk of becoming ill. There are, however, many other food items that are associated with an increased risk (even if not statistically significant).\nYou should next think about potential confounders and about effect modification. Think about which variables you might want to check for effect modification or confounding. One common strategy is to base this decision on the results obtained in the univariable analysis and a p-value threshold of 0.20-0.25. Also, food items that are known risk factors for gastroenteritis could also be included regardless of their univariable p-value."
  },
  {
    "objectID": "SimOb_RInject15.html#questionsassignments",
    "href": "SimOb_RInject15.html#questionsassignments",
    "title": "Stratified analysis",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments"
  },
  {
    "objectID": "SimOb_RInject15.html#confounders-and-effect-modification",
    "href": "SimOb_RInject15.html#confounders-and-effect-modification",
    "title": "Stratified analysis",
    "section": "3.1. Confounders and effect modification",
    "text": "3.1. Confounders and effect modification\nDiscuss how to identify potential confounders and effect modification. Draw dummy tables before coding to have clear what you want to achieve."
  },
  {
    "objectID": "SimOb_RInject15.html#consider-and-assess-for-confounding-andor-effect-modification",
    "href": "SimOb_RInject15.html#consider-and-assess-for-confounding-andor-effect-modification",
    "title": "Stratified analysis",
    "section": "3.4. Consider and assess for confounding and/or effect modification",
    "text": "3.4. Consider and assess for confounding and/or effect modification\nHave a look at the relative risk for being a case having eaten a specific food item (for example, moussake), when stratified by another variable (for example, orzo). You may consider stratifying by orzo, as it has the highest RR in the univariable analysis.\nThere are many variables in this dataset and it might not make sense to stratify each variable by each other variable on our search for effect modifiers and confounders.\nHowever, we also don’t want to be too restrictive as a variable which actually (i.e. causally) is associated with the outcome might not show a significant association at the significant level we decided (say 5%) in the univariable analysis due to confounding. Therefore, we could test all variables statistically significant at the 15%, 20%, or 25% level (specific percentage to be decided by your group). In our solutions here, we are looking at moussaka and champagne, stratified by orzo, but you may decide to look at other food items as well.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse the function csinter() of the EpiStats package.\n\n\n\n\na) Moussaka as exposure of interest, stratified by having eaten orzo\nIf we stratify the effect of moussaka by orzo we ask the question: does eating orzo modify or confound the association between eating moussaka and being a case?\n\n\nCode\nstratall &lt;- copdata %&gt;% \n  # Mutate across to convert cases to numeric:\n  mutate(across(.cols = case, \n                .fns = ~ as.numeric(.)))\n\n# Pass data to the csinter function:\norzostrata &lt;- csinter(x = stratall, \n                       cases = \"case\", \n                       exposure = \"moussaka\", \n                       by = \"orzo\")\n\norzostrata\n\n\n$df1\n  CSInter case - moussaka by(orzo) Total Cases Risk %          P.est. Stats\n1                         orzo = 1   338  &lt;NA&gt;     NA Risk difference  0.10\n2                          Exposed   330   198  60.00      Risk Ratio  1.20\n3                        Unexposed     8     4  50.00 Attrib.risk.exp  0.17\n4                                     NA  &lt;NA&gt;     NA Attrib.risk.pop  0.16\n5                         orzo = 0    36  &lt;NA&gt;     NA Risk difference  0.02\n6                          Exposed     8     3  37.50      Risk Ratio  1.05\n7                        Unexposed    28    10  35.71 Attrib.risk.exp  0.05\n8                                     NA  &lt;NA&gt;     NA Attrib.risk.pop  0.01\n9              Missing / Missing %     3  0.8%     NA            &lt;NA&gt;    NA\n  95%CI.ll 95%CI.ul\n1    -0.25     0.45\n2     0.60     2.41\n3    -0.68     0.59\n4       NA       NA\n5    -0.36     0.40\n6     0.38     2.92\n7    -1.65     0.66\n8       NA       NA\n9       NA       NA\n\n$df2\n                    Point Estimate Chi2 p.value  Stats 95%CI.ll 95%CI.ul\n1        Woolf test of homogeneity 0.04   0.833     NA       NA       NA\n2            Crude RR for moussaka   NA      NA   1.53     1.01     2.32\n3 MH RR moussaka adjusted for orzo   NA      NA   1.15     0.64     2.04\n4   Adjusted/crude relative change   NA      NA -25.08       NA       NA\n\n\nLet’s check if orzo is associated with moussaka (if we are thinking moussaka may be a confounder, we need to see if there is an association between the potential confounder (moussaka) and the exposure (orzo)):\n\n\nCode\n# Perform Wilcoxon rank sum test on orzo and moussaka:\nwilcox.test(orzo ~ moussaka, \n            data = copdata)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  orzo by moussaka\nW = 1496, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nb) Champagne as exposure of interest, stratified by having eaten orzo\n\n\nCode\n# Pass data to the csinter function:\nchampstrata &lt;- csinter(x = stratall, \n                       cases = \"case\", \n                       exposure = \"champagne\", \n                       by = \"orzo\")\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nAre there any indications to make you think there may be effect modification and/or confounding?\n\n\n\nWe could stratify by orzo (the strongest risk factor in the univariable analysis), to examine if orzo confounds the association between eating moussaka and being a case. Before stratification, we will need to check if orzo meets the conditions of being a confounder. For a variable to be a confounder it needs to be associated both with the outcome (being a case) and with the exposure (and not be in the causal pathway between exposure and outcome). We know from univariable analysis that orzo is associated with being a case. If we run a Wilcoxon rank sum test, we will see that orzo is also associated with moussaka (indeed, you can see that most people either had both moussaka and orzo or neither of these food items, so they are associated with each other).\nAbove, we uses ccinter to stratify and save the object as \"orzostrata\".\norzostrata: Within the stratum of the people who ate orzo, moussaka has no significant effect (RR = 1.20, CI: 0.60 - 2.41). The same holds within the stratum of people who didn't eat orzo (RR = 1.05, CI = 0.38, 2.92). The adjusted MH-RR also suggests that moussaka has no effect (RRadj = 1.15, CI: 0.80 - 2.85).  To identify confounding, we want to look at the % change between the crude and the adjusted RR. This is given by the csinter output \"Adjusted/crude relative change\".  The difference between the crude and the MH-RR in this case is &gt;20% suggesting that orzo confounds the association between moussaka and the disease.\nThis result suggest that moussaka is not a risk factor of the disease and that the crude observed effect was due to the confounding effect of orzo.\nIf you stratify by moussaka, you see that moussaka does not confound the association between orzo and the disease. The same applies if you stratify the exposure to orzo by other variables. The above, the higher RR for orzo and the dose response relationship we found earlier for orzo (remember this was optional) provide additional evidence that there was something going on with the orzo with pesto dish!"
  },
  {
    "objectID": "Data_import_cleaning.html",
    "href": "Data_import_cleaning.html",
    "title": "Data import and cleaning",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nImport datasets in R\nApply basic data management techniques to explore and familiarise themselves with the dataset\nApply strategies for data cleaning"
  },
  {
    "objectID": "Data_import_cleaning.html#install-packages-and-load-libraries",
    "href": "Data_import_cleaning.html#install-packages-and-load-libraries",
    "title": "Data import and cleaning",
    "section": "3.1. Install packages and load libraries",
    "text": "3.1. Install packages and load libraries\n\nLoad the R packages you will be using. Update this list of packages as you dig into the code: You may realise you need packages you didn’t think about at the beginning. Remember that it is a good practice to load tydiverse at the end of your package list, to avoid masking functions.\n\n\n\nShow the code\n# Check if the 'pacman' package is installed, if not install it:\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales,\n               tidyverse \n)"
  },
  {
    "objectID": "Data_import_cleaning.html#import-your-data",
    "href": "Data_import_cleaning.html#import-your-data",
    "title": "Data import and cleaning",
    "section": "3.2. Import your data",
    "text": "3.2. Import your data\n\nYou can find the spetses_school.csv file in EVA. Feel free to explore the codebook as well.\n\n\n\nShow the code\n# Import the raw data set:\ncopdata &lt;- import(here::here(\"data\", \"spetses_school.csv\"))"
  },
  {
    "objectID": "Data_import_cleaning.html#explore-and-clean-your-data",
    "href": "Data_import_cleaning.html#explore-and-clean-your-data",
    "title": "Data import and cleaning",
    "section": "3.3. Explore and clean your data",
    "text": "3.3. Explore and clean your data\n\nHave a look at the structure of your data. Here you have some questions that may help you get started:\n\nHow many observations and variables does the dataset contain?\nWhat types of variables do you have and what types of values are recorded?\nDo any of the values of the other variables look implausible? Which ones and why? What will you do about it?\n\nGo ahead and clean your data as you see fit.\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nYou could use head(), dim(), str(), or skim() to have a quick look at the data and get an idea of which variables you want to explore further. You can also do some tables\n\n\n\n\n\nShow the code\nhead(copdata)\n\n\n\n  \n\n\n\nShow the code\ndim(copdata)\n\n\n[1] 397  41\n\n\nShow the code\nstr(copdata)\n\n\n'data.frame':   397 obs. of  41 variables:\n $ id        : chr  \"sp-2-001\" \"sp-3-003\" \"sp-1-005\" \"sp-2-006\" ...\n $ sex       : chr  \"male\" \"female\" \"female\" \"male\" ...\n $ age       : int  18 18 17 17 18 180 16 15 43 16 ...\n $ group     : int  1 1 1 1 1 1 0 1 0 1 ...\n $ class     : int  2 3 1 2 3 2 NA 1 NA 1 ...\n $ ill       : int  1 0 1 0 1 1 0 1 1 0 ...\n $ diarrhoea : int  1 NA NA NA 1 1 NA 0 1 NA ...\n $ bloody    : int  0 NA NA NA 0 0 NA 0 NA NA ...\n $ vomiting  : int  0 NA NA NA 0 0 NA 0 NA NA ...\n $ abdo      : int  1 NA 1 NA 1 1 NA 0 NA NA ...\n $ nausea    : int  0 NA 1 NA 1 0 NA 1 1 NA ...\n $ fever     : int  NA NA NA NA 0 0 NA 0 NA NA ...\n $ headache  : int  0 NA 1 NA 1 0 NA 1 1 NA ...\n $ jointpain : int  0 NA NA NA 0 0 NA 0 1 NA ...\n $ starthour : int  9 NA NA NA 15 15 NA NA 3 NA ...\n $ meal      : int  1 1 1 0 1 1 1 1 1 1 ...\n $ feta      : int  1 0 NA 0 1 1 1 1 1 1 ...\n $ fetaD     : int  2 0 NA 0 2 2 2 1 2 2 ...\n $ sardines  : int  1 0 NA 0 1 1 1 0 1 1 ...\n $ sardinesD : int  2 0 NA 0 2 2 2 0 2 2 ...\n $ eggplant  : int  0 0 NA 0 1 1 1 0 NA 1 ...\n $ eggplantD : int  0 0 NA 0 2 2 2 0 NA 2 ...\n $ veal      : int  1 1 1 1 1 1 1 1 1 1 ...\n $ vealD     : int  2 1 0 0 2 2 1 3 2 2 ...\n $ pasta     : int  1 1 1 0 1 1 1 1 1 1 ...\n $ pastaD    : int  3 3 1 0 2 2 2 3 2 3 ...\n $ tomsal    : int  1 1 NA 0 1 1 1 1 1 1 ...\n $ tomsalD   : int  1 3 NA 0 2 2 2 2 2 2 ...\n $ bread     : int  1 1 1 0 1 1 1 1 1 1 ...\n $ breadD    : int  2 3 1 0 2 2 2 2 2 2 ...\n $ dessert   : int  1 1 NA 0 1 1 0 1 NA NA ...\n $ dessertD  : int  2 3 NA 0 2 2 0 1 NA NA ...\n $ champagne : int  1 1 0 1 1 1 1 1 1 1 ...\n $ champagneD: int  1 1 0 3 1 1 2 1 1 1 ...\n $ beer      : int  1 0 0 1 1 1 NA 1 NA 1 ...\n $ beerD     : int  3 0 0 3 2 3 NA 1 NA 2 ...\n $ redwine   : int  0 1 0 1 0 0 1 0 1 0 ...\n $ redwineD  : int  0 3 0 3 0 0 2 0 2 0 ...\n $ whitewine : int  0 0 0 1 1 1 1 1 NA 0 ...\n $ whitewineD: int  0 0 0 3 3 2 1 3 NA 0 ...\n $ dayonset  : chr  \"6oct2024\" \"\" \"\" \"\" ...\n\n\nShow the code\nskim(copdata)\n\n\n\nData summary\n\n\nName\ncopdata\n\n\nNumber of rows\n397\n\n\nNumber of columns\n41\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n8\n8\n0\n397\n0\n\n\nsex\n0\n1\n4\n6\n0\n2\n0\n\n\ndayonset\n0\n1\n0\n8\n175\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1.00\n18.57\n9.92\n8\n16\n17\n18\n180\n▇▁▁▁▁\n\n\ngroup\n0\n1.00\n0.96\n0.20\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nclass\n36\n0.91\n1.94\n0.84\n1\n1\n2\n3\n3\n▇▁▆▁▇\n\n\nill\n0\n1.00\n0.69\n0.47\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\ndiarrhoea\n141\n0.64\n0.82\n0.39\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nbloody\n200\n0.50\n0.03\n0.17\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nvomiting\n179\n0.55\n0.30\n0.46\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nabdo\n152\n0.62\n0.85\n0.35\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nnausea\n170\n0.57\n0.76\n0.43\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nfever\n223\n0.44\n0.26\n0.44\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nheadache\n174\n0.56\n0.63\n0.48\n0\n0\n1\n1\n1\n▅▁▁▁▇\n\n\njointpain\n207\n0.48\n0.16\n0.37\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nstarthour\n177\n0.55\n12.49\n4.92\n3\n9\n9\n15\n21\n▁▇▁▆▃\n\n\nmeal\n9\n0.98\n0.97\n0.17\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nfeta\n16\n0.96\n0.71\n0.45\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\nfetaD\n16\n0.96\n1.32\n1.00\n0\n0\n2\n2\n3\n▆▅▁▇▂\n\n\nsardines\n17\n0.96\n0.67\n0.47\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\nsardinesD\n17\n0.96\n1.34\n1.04\n0\n0\n2\n2\n3\n▆▂▁▇▂\n\n\neggplant\n30\n0.92\n0.59\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\neggplantD\n30\n0.92\n1.14\n1.05\n0\n0\n1\n2\n3\n▇▂▁▇▂\n\n\nveal\n15\n0.96\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nvealD\n14\n0.96\n1.83\n0.91\n0\n1\n2\n2\n3\n▂▃▁▇▃\n\n\npasta\n15\n0.96\n0.88\n0.32\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\npastaD\n15\n0.96\n1.81\n0.91\n0\n1\n2\n2\n3\n▂▃▁▇▃\n\n\ntomsal\n24\n0.94\n0.57\n0.50\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\ntomsalD\n24\n0.94\n1.08\n1.06\n0\n0\n1\n2\n3\n▇▂▁▆▂\n\n\nbread\n18\n0.95\n0.91\n0.29\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nbreadD\n18\n0.95\n1.75\n0.71\n0\n2\n2\n2\n3\n▁▂▁▇▁\n\n\ndessert\n42\n0.89\n0.42\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▆\n\n\ndessertD\n42\n0.89\n0.83\n1.06\n0\n0\n0\n2\n3\n▇▁▁▃▁\n\n\nchampagne\n25\n0.94\n0.87\n0.34\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nchampagneD\n25\n0.94\n1.37\n0.93\n0\n1\n1\n2\n3\n▂▇▁▂▃\n\n\nbeer\n30\n0.92\n0.78\n0.42\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nbeerD\n35\n0.91\n1.94\n1.23\n0\n1\n3\n3\n3\n▃▂▁▂▇\n\n\nredwine\n50\n0.87\n0.23\n0.42\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nredwineD\n52\n0.87\n0.45\n0.92\n0\n0\n0\n0\n3\n▇▁▁▁▁\n\n\nwhitewine\n31\n0.92\n0.73\n0.45\n0\n0\n1\n1\n1\n▃▁▁▁▇\n\n\nwhitewineD\n36\n0.91\n1.58\n1.21\n0\n0\n2\n3\n3\n▆▅▁▅▇\n\n\n\n\n\nShow the code\nnames(copdata)\n\n\n [1] \"id\"         \"sex\"        \"age\"        \"group\"      \"class\"     \n [6] \"ill\"        \"diarrhoea\"  \"bloody\"     \"vomiting\"   \"abdo\"      \n[11] \"nausea\"     \"fever\"      \"headache\"   \"jointpain\"  \"starthour\" \n[16] \"meal\"       \"feta\"       \"fetaD\"      \"sardines\"   \"sardinesD\" \n[21] \"eggplant\"   \"eggplantD\"  \"veal\"       \"vealD\"      \"pasta\"     \n[26] \"pastaD\"     \"tomsal\"     \"tomsalD\"    \"bread\"      \"breadD\"    \n[31] \"dessert\"    \"dessertD\"   \"champagne\"  \"champagneD\" \"beer\"      \n[36] \"beerD\"      \"redwine\"    \"redwineD\"   \"whitewine\"  \"whitewineD\"\n[41] \"dayonset\"  \n\n\nLet’s explore and manage some variables in detail.\n\nAge\nThrough visual exploration of the age histogram we see that there is at least one very high value, likely implausible. You can then create a cross-tabulation of variables age and group to have a better idea of how your data looks like.\n\n\nShow the code\n# Have a look at the histogram  \nhist(copdata$age)   \n\n\n\n\n\n\n\n\n\nShow the code\n# Create cross-tab with the group variable:  \ntabyl(dat = copdata, \n               var1 = age, \n               var2 = group)\n\n\n\n  \n\n\n\nNote that group is coded as 0 and 1, and these may be difficult to interpret when they mean something other than “no” and “yes”, respectively. From the codebook, you know that teachers are represented by 0, and students by 1. Let’s change this to make our lives easier:\n\n\nShow the code\n# Convert group to a factor and label 0 as teacher, 1 as student:\ncopdata &lt;- copdata %&gt;% \n  mutate(group = factor(group, \n                        labels = c(\"teacher\", \"student\")))\n\n\nNow, have a look at your cross-tab again:\n\n\nShow the code\ntabyl(dat = copdata, \n               var1 = age, \n               var2 = group) \n\n\n\n  \n\n\n\nWith this table, we can more easily identify ages that are likely to be typographic errors. Specifically:\n\nThere is one teacher aged 16 (likely digit reversal - should be 61)\nThere is one student aged 8 (likely missing a digit - should be 18)\nThere is one student aged 180 (likely has an extra digit - should be 18)\n\nAssuming you have contacted the school to make sure your suspicions about the actual ages are correct, we can now correct them, using case_when(). We create logical conditions to identify the incorrect ages, combining the values for age with the group they belong to:\n\n\nShow the code\n# Update incorrect ages to the correct values with case_when:  \ncopdata &lt;- copdata %&gt;%       \n  mutate(age =                         \n           case_when(                            \n             # Where respondent is 16 and a teacher, change age to 61:\n             age == 16 & group == \"teacher\" ~ 61,              \n             # where respondent is 8 or 180 and a student, change age to 18:\n             age == 8 & group == \"student\" ~ 18,              \n             age == 180 & group == \"student\" ~ 18,              \n             # Keep remaining values as is:              \n             .default = as.numeric(age)   \n             # if .default is not working, try:\n             # TRUE ~ age\n             )                    \n         ) \n\n\n\n\n\n\n\n\nCreate summary table for the dose response columns (those finishing with a capital “D”) to have a look at their distribution.\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse gtsummary::tbl_summary().\n\n\n\n\n\nShow the code\n#| label: check_dose_cols\n#| tbl-cap: no caption\n\n# Create summary table for dose response columns: \ndrtable &lt;- copdata %&gt;%       \n  # Select all the columns with column names that end in upper case 'D':   \n  select(ends_with(\"D\", ignore.case = FALSE)) %&gt;%       \n  # Create the summary table, excluding missing values:   \n  tbl_summary(missing = \"no\") \n\n  # Print the summary table: \ndrtable\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 3971\n\n\n\n\nfetaD\n\n\n\n\n    0\n110 (29%)\n\n\n    1\n78 (20%)\n\n\n    2\n155 (41%)\n\n\n    3\n38 (10.0%)\n\n\nsardinesD\n\n\n\n\n    0\n125 (33%)\n\n\n    1\n35 (9.2%)\n\n\n    2\n184 (48%)\n\n\n    3\n36 (9.5%)\n\n\neggplantD\n\n\n\n\n    0\n151 (41%)\n\n\n    1\n41 (11%)\n\n\n    2\n147 (40%)\n\n\n    3\n28 (7.6%)\n\n\nvealD\n\n\n\n\n    0\n42 (11%)\n\n\n    1\n70 (18%)\n\n\n    2\n184 (48%)\n\n\n    3\n87 (23%)\n\n\npastaD\n\n\n\n\n    0\n44 (12%)\n\n\n    1\n70 (18%)\n\n\n    2\n183 (48%)\n\n\n    3\n85 (22%)\n\n\ntomsalD\n\n\n\n\n    0\n162 (43%)\n\n\n    1\n52 (14%)\n\n\n    2\n126 (34%)\n\n\n    3\n33 (8.8%)\n\n\nbreadD\n\n\n\n\n    0\n35 (9.2%)\n\n\n    1\n51 (13%)\n\n\n    2\n267 (70%)\n\n\n    3\n26 (6.9%)\n\n\ndessertD\n\n\n\n\n    0\n206 (58%)\n\n\n    1\n33 (9.3%)\n\n\n    2\n87 (25%)\n\n\n    3\n29 (8.2%)\n\n\nchampagneD\n\n\n\n\n    0\n49 (13%)\n\n\n    1\n208 (56%)\n\n\n    2\n45 (12%)\n\n\n    3\n70 (19%)\n\n\nbeerD\n\n\n\n\n    0\n81 (22%)\n\n\n    1\n41 (11%)\n\n\n    2\n57 (16%)\n\n\n    3\n183 (51%)\n\n\nredwineD\n\n\n\n\n    0\n266 (77%)\n\n\n    1\n31 (9.0%)\n\n\n    2\n21 (6.1%)\n\n\n    3\n27 (7.8%)\n\n\nwhitewineD\n\n\n\n\n    0\n100 (28%)\n\n\n    1\n73 (20%)\n\n\n    2\n67 (19%)\n\n\n    3\n121 (34%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "Data_import_cleaning.html#modify-variables-format",
    "href": "Data_import_cleaning.html#modify-variables-format",
    "title": "Data import and cleaning",
    "section": "3.4. Modify variables format",
    "text": "3.4. Modify variables format\nThere are some “column types” you would like to modify because either R needs some specific types of data when working with certain variables, or because it will be easier for you to visualise and interpret the data. For example, the variable “group” is encoded as 0 and 1, when you create a table later on, you don’t want to see 0’s and 1’s because that doesn’t mean anything. It is better to change this variable to a factor, with explicit labels, so they actually mean something when they come out in your table.\n\n\n\n\n\nYou can use mutate to modify the type of the following variables:\n\nTable 1: Variable types to modify\n\n\n\n\n\n\n\n\nVariable name\nOriginal\nDesired\nHint\n\n\n\n\nsex\ncharacter\nfactor\nmutate(), as.factor()\n\n\nclass\ninteger\nfactor\nmutate(), as.factor()\n\n\nill\ninteger\nfactor\nmutate(), as.factor()\n\n\nAll the clinical symptom variables\ninteger\nfactor\nmutate(across()), as.factor()\n\n\nAll the food variables representing the amount of specific foods eaten (those finishing with a capital “D”)\ninteger\nfactor\nmutate(across()), as.factor()\n\n\ndayonset\ncharacter\ndate\nlubridate::dmy()\n\n\nstarthour and dayonset together\ninteger (starthour)\ndate (dayonset)\nPOSIXct, POSIXt\nlubridate::ymd_h() could have inside stringr::str_glue() with dayonset and starthour\n\n\n\n\nSex, class and ill\nLet’s start transforming one-by-one the first three variables in the table: sex, class and ill.\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  mutate(\n    sex = as.factor(sex),\n    class = as.factor(class),\n    ill = as.factor(ill))\n\n\n\n\nSymptoms and Food variables\nFor these variables, we are going to show you a couple of different ways to carry out the same variable type transformation in a set of variables, so you don’t need to do one variable at a time. We are showing you these ways so you see alternative ways to do the same thing.\n\nFor the variables that are clinical symptoms, we will list them one by one and show you the use of mutate(across( )).\n\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  mutate(\n    # clinical symptoms\n    across(.cols = c(diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain), \n           .fns = ~ as.factor(.)\n           )\n    )\n\n\n\nFor the variables that are food doses, we will show you how to first create a vector of names, following by using mutate(across(all_of( ))) on this vector.\n\n\n\nShow the code\n# Create a vector with all the food variables representing the amount of specific foods items eaten (those finishing with a capital \"D\")\n# One way of doing it:\nfood_dose &lt;- copdata %&gt;% \n    select(\n      ends_with(\"D\", ignore.case = FALSE)) %&gt;% \n    names()\n\n# Another way of doing it:\n# food_dose &lt;- c(\"fetaD\", \"sardinesD\", \"eggplantD\", \"pastaD\", \n#                 \"vealD\", \"greeksalD\", \"dessertD\", \"breadD\", \n#                 \"champagneD\", \"beerD\", \"redwineD\", \"whitewineD\")\n\n\ncopdata &lt;- copdata %&gt;% \n  mutate(\n    # food dose variables\n    across(.cols = all_of(food_dose), \n           .fns = ~as.factor(.))) \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe tilde (~) above is used to apply the transformation as.factor(.) to each selected column, which in our case is either all columns included in food_items and food_dose.\n\n\n\n\n\nDate and time variables\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhy may you want to transform the variable starthour to date-time?\n\n\n\n\n\n\n\n\nYou can use lubridate::dmy() to mutate the dayonset variable into a date variable. Note that we are using the function dmy() because dates are formatted as day, then month (abbreviated character string), then year (i.e. “12nov2006”).\n\n\nShow the code\n# Have a look at how the data is stored\nhead(copdata$dayonset)\n\n\n[1] \"6oct2024\" \"\"         \"\"         \"\"         \"6oct2024\" \"7oct2024\"\n\n\nShow the code\nclass(copdata$dayonset)\n\n\n[1] \"character\"\n\n\nShow the code\n# Update copdata:\ncopdata &lt;- copdata %&gt;% \n  # Change column to date class:\n  mutate(\n    dayonset = lubridate::dmy(dayonset))\n\n# Check class of updated column:\nclass(copdata$dayonset)\n\n\n[1] \"Date\"\n\n\nShow the code\n# Have a look at your data now:\nhead(copdata$dayonset)\n\n\n[1] \"2024-10-06\" NA           NA           NA           \"2024-10-06\"\n[6] \"2024-10-07\"\n\n\nHaving a variable that defines “time” in an outbreak investigation can be very useful when creating a case definition. An hour of the day, without a date associated with it doesn’t help you much, thus, you should merge together day and time of onset of symptoms into a single variable. Moreover, you will be using this combined variable later on to estimate an incubation period and create your epicurve. We can combine these two variables by using the lubridate::ymd_h() function.\nBefore we proceed, it would be wise to check if any respondents have a value for dayonset but not starthour, or vice versa. The lubridate date-time conversion functions do not have an explicit argument for dealing with missing values, but the truncated = … argument can help prevent spurious date-times being derived from a date-time combination where one value is missing.\nWe can check if we have any missing values by cross-tabulating starthour with dayonset:\n\n\nShow the code\n# Cross-tabulate dayonset with starthour:\ntabyl(dat = copdata, \n               var1 = starthour, \n               var2 = dayonset)\n\n\n\n  \n\n\n\nThis shows us that there are two respondents who had an onset date, but are missing onset time (starthour). Since starthour is represented by 1 - 2 digits, we can specify that we want lubridate to also parse date-time combinations that are truncated by up to two digits:\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  # Combine dayonset and starthour in a new date time variable:\n  mutate(onset_datetime = \n           ymd_h(\n             str_glue(\"{dayonset}, {starthour}\"), \n                                           # Deal with missing starthour:\n                                           truncated = 2))\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `onset_datetime = ymd_h(str_glue(\"{dayonset}, {starthour}\"),\n  truncated = 2)`.\nCaused by warning:\n!  175 failed to parse.\n\n\nNote that we needed to use str_glue() to concatenate dayonset and starthour together before we could convert the variable to a date-time object. This is because the ymd_h() function expects a single character string, containing both the date and the time, as input.\nThe argument truncated = 2 will result in dates with missing starthour still being converted to date-time, with the missing time being set to 00:00 (midnight). Whether you want to deal with missing starthour in this way or prefer to code these date-times as NA will depend on how you want them to be represented in your analysis.\nNow we can check that everything in the new combined date-time variable has parsed correctly:\n\n\nShow the code\nhead(copdata$dayonset)\n\n\n[1] \"2024-10-06\" NA           NA           NA           \"2024-10-06\"\n[6] \"2024-10-07\"\n\n\nShow the code\nhead(copdata$starthour)\n\n\n[1]  9 NA NA NA 15 15\n\n\nShow the code\nhead(copdata$onset_datetime)\n\n\n[1] \"2024-10-06 09:00:00 UTC\" NA                       \n[3] NA                        NA                       \n[5] \"2024-10-06 15:00:00 UTC\" \"2024-10-07 15:00:00 UTC\""
  },
  {
    "objectID": "Data_import_cleaning.html#export-clean-data",
    "href": "Data_import_cleaning.html#export-clean-data",
    "title": "Data import and cleaning",
    "section": "3.5. Export clean data",
    "text": "3.5. Export clean data\nSave the cleaned data set before proceeding with using your case definition to identify cases in your dataset. Use the .rds format, as it preserves column classes. This ensures you will have only minimal cleaning to do after importing the data into R at the next inject.\nSave your clean data as a new file “Spetses_clean1_YOURINITIALS.rds”, under the data folder of your Rproject.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse rio::export().\n\n\n\n\n\nShow the code\nexport(x = copdata, \n            file = here::here(\"data\", \"Spetses_clean1_2024.rds\"))"
  },
  {
    "objectID": "Lab_and_Descriptive.html",
    "href": "Lab_and_Descriptive.html",
    "title": "Laboratory data and descriptive analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nMerge two datasets using a common column.\nDiscuss which descriptive statistics would you use to describe the cases\nDescribe the cases by person and place (this is an outbreak in a high school, so we won’t explore “place” this time!)\nGenerate preliminary hypotheses bases on the descriptions."
  },
  {
    "objectID": "Lab_and_Descriptive.html#learning-outcomes",
    "href": "Lab_and_Descriptive.html#learning-outcomes",
    "title": "Laboratory data and descriptive analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nMerge two datasets using a common column.\nDiscuss which descriptive statistics would you use to describe the cases\nDescribe the cases by person and place (this is an outbreak in a high school, so we won’t explore “place” this time!)\nGenerate preliminary hypotheses bases on the descriptions."
  },
  {
    "objectID": "Lab_and_Descriptive.html#storyplot-description",
    "href": "Lab_and_Descriptive.html#storyplot-description",
    "title": "Laboratory data and descriptive analysis",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nYou have received the laboratory results for the samples collected from some of the cases. The lab conducted an RT-PCR panel targeting various gastrointestinal pathogens and also gathered additional metadata. Your task is to merge the questionnaire data with the data you have received from the lab, using the unique identifiers that both datasets share (id column), and explore that lab data. What does it tell you?\nOnce your dataset is clean and the lab data merged, you can describe the people identified as cases so far and generate a hypothesis to inform the next steps in the outbreak investigation. Note that you should try to have a data analysis plan before any data collection. Nevertheless, during the urgency of outbreak investigations, questionnaire development may sometimes occur before you had time to draft a proper analysis plan (as it is the case in this simulated outbreak). Drawing “dummy” tables and graphs will help you precise the type of statistics you will carry out later on."
  },
  {
    "objectID": "Lab_and_Descriptive.html#questionsassignments",
    "href": "Lab_and_Descriptive.html#questionsassignments",
    "title": "Laboratory data and descriptive analysis",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments\nIf you closed your R project, please open it again and load the clean dataset. We recommend you use the Spetses_clean2_2024.rds. This is just to be sure all needed changes in that file for the code to work have been done (as you may have changed the file in a slightly different way than we have)."
  },
  {
    "objectID": "Lab_and_Descriptive.html#install-packages-if-needed-and-load-libraries",
    "href": "Lab_and_Descriptive.html#install-packages-if-needed-and-load-libraries",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.1 Install packages (if needed) and load libraries",
    "text": "3.1 Install packages (if needed) and load libraries\n\n\nShow the code\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "Lab_and_Descriptive.html#import-your-data",
    "href": "Lab_and_Descriptive.html#import-your-data",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.2 Import your data",
    "text": "3.2 Import your data\n\n\nShow the code\n# Import the clean data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"Spetses_clean2_2024.rds\"), trust = T) \nlab &lt;- rio::import(here::here(\"data\", \"Lab data.xlsx\"),\n                   skip = 1) # skip the first row."
  },
  {
    "objectID": "Lab_and_Descriptive.html#merge-and-explore-the-lab-data",
    "href": "Lab_and_Descriptive.html#merge-and-explore-the-lab-data",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.3 Merge and explore the lab data",
    "text": "3.3 Merge and explore the lab data\n\n\nCode\ncopdatalab &lt;- left_join(copdata, lab, by = \"id\")\n# Tabulate:\njanitor::tabyl(dat = copdatalab, result)"
  },
  {
    "objectID": "Lab_and_Descriptive.html#describe-the-outbreak-in-terms-of-time.",
    "href": "Lab_and_Descriptive.html#describe-the-outbreak-in-terms-of-time.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.4 Describe the outbreak in terms of time.",
    "text": "3.4 Describe the outbreak in terms of time.\nYou could use ggplot2.To learn more about ggplot2 you can check The Epidemiologist R Handbook: Chapter on ggplot and ggplot2 - Elegant Graphics for Data Analysis.\n\na) Create a histogram to visualize the incubation period (geom_histogram is a good function to use for this!).\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat can you infer from the incubation periods in the histogram?\n\n\n\n\n\nShow the code\n#| label: inc_time\n\n# Create a dataset with only cases\ncases &lt;- copdata %&gt;% \n  filter(case == 1)\n\nincplot &lt;- cases %&gt;% \n  # Create an empty ggplot frame:\n  ggplot() +\n  # Add a histogram of incubation:\n  geom_histogram(\n    mapping = aes(x = incubation), \n    # Set bin widths to 6 hours:\n    binwidth = 6) +\n  # Adapt scale to better fit data\n  scale_x_continuous(breaks = seq(0, 48, 6)) + \n  # Label x and y axes:\n  labs(x = \"Incubation period in 6-hour bins\",\n       y = \"Number of cases\")\n\n# Print plot:\nincplot\n\n\n\n\n\n\n\n\n\n\n\nb) Create an epicurve for the date and time of onset (using onset_datetime), limiting the input data to cases.\n\nUse scale_x_datetime() and chose a value for date_breaks() based on your calculated incubation period.\nLabel your x and y axes using labs().\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nA rule of thumb is to use one third or one fourth of the average incubation period as an interval. For our investigation this means we should use approximately a 6h interval for the date_breaks argument.\n\n\n\n\n\nShow the code\n# Create a vector with sequences every 6h from the first to the last case\nbreaks_6h &lt;- seq(from = min(cases$onset_datetime, na.rm = TRUE),\n                 to = max(cases$onset_datetime, na.rm = TRUE),\n                 by = \"6 hours\")\n\n# Fetch cases data:\nepicurve_datetime &lt;- cases %&gt;%  \n  # Add factor onset_datetime to ggplot aesthetic:\n  ggplot(\n    mapping = aes(x = onset_datetime)) + \n  # Add geom_histogram:\n  geom_histogram(\n    # Apply the vector of requences created above\n    breaks = breaks_6h) +\n  # Adapt scale to data and adjust axis label angle:\n  scale_x_datetime(\n    date_breaks = \"6 hours\",\n    labels = label_date_short()) +\n  # Update x and y axis labels:\n  labs(x = \"Date and time of onset symptoms\", \n       y = \"Number of cases\") +\n  # Remove unnecessary grid lines:\n  theme_bw()\n\n# Print epicurve:\nepicurve_datetime\n\n\n\n\n\n\n\n\n\n\nBuilding up on your previous epicurve, create another epicurve to compare between sexes and additionally investigate how teachers versus students were distributed.\n\n\nUse fill = group\nUse sex as your facets for facet_wrap()\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nfill adds an additional variable to be displayed in the plot: group is going to determine the fill-colour of our bars. facet_wrap splits the graph in two: one each for the two levels of sex.\n\n\n\n\n\n\n\n\n\nDo you feel like a challenge?\n\n\n\n\n\nIf you want, try using str_glue() to add the total number of cases to the sub-title of the plot. str_glue() is a very useful function that allows you to dynamically create a summary statistic from your data within some normal text.\n\n\n\n\n\nShow the code\nepicurve_strata &lt;- cases %&gt;% \n  # Add factor onset_day to ggplot aesthetic:\n  ggplot(\n    mapping = aes(x = onset_datetime, fill = group)) + \n  # Add nicer fill colours:\n  scale_fill_manual(values = c(\"darkred\", \"lightblue\")) +\n    # Add geom_histogram:\n  geom_histogram(\n    # Apply the vector of requences created above\n    breaks = breaks_6h) +\n  # Adjust x axis scales to a suitable unit:\n  scale_x_datetime(\n    date_breaks = \"6 hours\", \n    labels = label_date_short()) +\n  # Update x and y axis labels:\n  labs(x = \"Date and time of onset\", \n       y = \"Number of cases\", \n       fill = \"Group\", \n       title = \"Epicurve of the outbreak, stratified by sex\",\n       subtitle = str_glue(\"Spetses, October 2024, N = {sum(copdata$case)}\")) +\n  # Stratify by sex:\n  facet_wrap(facets = \"sex\",\n             ncol = 2) +\n  # Add theme:\n  theme_bw()\n\n# Print epicurve:\nepicurve_strata \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat does the stratified epicurve tell you? Does the shape of the epicurve support a viral or toxic aetiology? What other information can you obtain from it?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above questions, have a look here\n\n\n\n\n\nWhen constructing an epicurve, we need to decide on the resolution, i.e. the time interval for a single bar. A rule of thumb is to use one third or one fourth of the average incubation period as an interval. For our investigation this means we should use approximately a 6h interval.\nThis seems a good choice, as we saw that the daily interval was too coarse to really see the signal we are after. The epicurve and the summary of the incubation period show that there seemed to be a rapid onset of symptoms following exposure. This is in line with our previous suspicion that a virus or a toxin might be the causative agent in the outbreak.\nThe unimodal shape with the sharp peak suggests a point source, while the tail on the right-hand side could be explained by secondary cases or background noise. Also, people that only consumed a little contaminated food and therefore only a low infectious dose could have a longer incubation period and could explain the late cases.\nThe above results are in line with norovirus as the prime suspect, but the symptoms are not a textbook fit. There are too few people that experienced vomiting! Looking forward to receiving the lab results!"
  },
  {
    "objectID": "Lab_and_Descriptive.html#describe-the-outbreak-in-terms-of-person.",
    "href": "Lab_and_Descriptive.html#describe-the-outbreak-in-terms-of-person.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.5. Describe the outbreak in terms of person.",
    "text": "3.5. Describe the outbreak in terms of person.\nYou could use tabyl(). For more detail on the tabyl() function and the adorn_XYZ helpers, see the janitor documentation or The Epidemiologist R Handbook section on tabulation.\n\na) Create a cross-tabulation of case with group.\n\n\nShow the code\ncopdata %&gt;% \n  janitor::tabyl(case, group) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() \n\n\n\n  \n\n\n\n\n\nb) Create a cross-tabulation of case with sex.\n\n\nShow the code\ncopdata %&gt;% \n  janitor::tabyl(case, sex) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() \n\n\n\n  \n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do you think of these results?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above questions, have a look here\n\n\n\n\n\nThe distribution of the cohort regarding sex, group and class also didn’t reveal anything unusual. Students seem a bit more affected by the outbreak than teachers and the attack rate is higher for older students in higher classes. This, however, is a purely descriptive result.\n\n\n\n\n\n\n\n\n\nDo you feel like a challenge?\n\n\n\n\n\nIf you want, create an age-sex pyramid using the apyramid package. To do so, first create an age category variable with the epkit function age_categories().\n\n\n\n\n\nc) Extra - Age-sex pyramid of cases.\nHint: Change show_midpoint = FALSE to TRUE to see skewedness in the data patterns more easily.\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  # Create age categories:\n  mutate(age_cat = epikit::age_categories(\n    # Name of age column:\n    x = age, \n    # Define the age categories:\n    breakers = c(0, 10, 16, 18, 20, 50, 70)\n    )\n  )\n\n\n# Check age categories:\njanitor::tabyl(copdata, age_cat)\n\n\n\n  \n\n\n\nShow the code\n# Pipe copdata:\nagesex &lt;- copdata %&gt;% \n  # Filter for cases only:\n  filter(case == TRUE) %&gt;% \n  # Create age sex pyramid:\n  apyramid::age_pyramid(\n  # Specify column containing age categories:\n    age_group = \"age_cat\",\n    # Specify column containing sex:\n    split_by = \"sex\", \n    # Don't show midpoint on the graph:\n    show_midpoint = FALSE\n    )\n\n# Print plot:\nagesex"
  },
  {
    "objectID": "Lab_and_Descriptive.html#explore-the-distribution-of-all-clinical-signs-symptoms.",
    "href": "Lab_and_Descriptive.html#explore-the-distribution-of-all-clinical-signs-symptoms.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.6 Explore the distribution of all clinical signs (symptoms).",
    "text": "3.6 Explore the distribution of all clinical signs (symptoms).\n\na) Create a summary table with symptoms stratified by case definition, and present an overall column as well. You could use tabyl() or gtsummary::tbl_summary(). You can find further information about gtsummary in The Epidemiologist R handbook section on gtsummary.\n\n\nShow the code\n# Create summary table:\ntabsymptoms &lt;- copdata %&gt;% \n    # Select person characteristics to summarise:\n  select(case, diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain) %&gt;% \n  # transform clinical symptoms to factors, so NA can be accounted properly in the table\n  dplyr::mutate(\n    across(.cols = c(diarrhoea, bloody, vomiting,\n             abdo, nausea, fever,headache, jointpain), \n           .fns = ~as.factor(.))) %&gt;%\n  # The enxt paragraph does not work with Rversion 4.4.0\n  # Make NA a explicit level of factor variables\n  # dplyr::mutate(\n  #   across(.cols = c(diarrhoea, bloody, vomiting,\n  #          abdo, nausea, fever,headache, jointpain),\n  #          .fns = ~forcats::fct_na_value_to_level(.))) %&gt;% \n     \n  # Create the summary table:\n  gtsummary::tbl_summary(\n    # Stratify by case:\n    by = case, \n    # take care of missing values\n    missing = \"no\", \n    # Calculate row percentages:\n    percent = \"column\",\n    # Create nice labels:\n    label  = list(\n      diarrhoea   ~ \"Diarrhoea\",                           \n      bloody      ~ \"Dysentary\",\n      vomiting    ~ \"Vomiting\",\n      abdo        ~ \"Abdominal pain\",\n      nausea      ~ \"Nausea\", \n      fever       ~ \"Fever\", \n      headache    ~ \"Headache\", \n      jointpain   ~ \"Joint pain\")\n    \n  ) %&gt;% \n  \n  # Add totals:\n  add_overall() %&gt;% \n  # Make variable names bold and italics:\n  bold_labels() %&gt;% \n  italicize_labels() %&gt;% \n  # Modify header:\n  modify_header(\n    label = \"**Characteristic**\",\n    stat_0 = \"**Overall**\\n **N** = {N}\",\n    stat_1 = \"**Non-case**\\n **N** = {n}\",\n    stat_2 = \"**Case**\\n **N** = {n}\", \n    )\n\n# Print the table:\ntabsymptoms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall N = 3771\nNon-case N = 1611\nCase N = 2161\n\n\n\n\nDiarrhoea\n\n\n\n\n\n\n\n\n    0\n46 (18%)\n40 (100%)\n6 (2.8%)\n\n\n    1\n206 (82%)\n0 (0%)\n206 (97%)\n\n\nDysentary\n\n\n\n\n\n\n\n\n    0\n189 (97%)\n42 (100%)\n147 (97%)\n\n\n    1\n5 (2.6%)\n0 (0%)\n5 (3.3%)\n\n\nVomiting\n\n\n\n\n\n\n\n\n    0\n149 (69%)\n42 (100%)\n107 (62%)\n\n\n    1\n66 (31%)\n0 (0%)\n66 (38%)\n\n\nAbdominal pain\n\n\n\n\n\n\n\n\n    0\n35 (14%)\n6 (12%)\n29 (15%)\n\n\n    1\n207 (86%)\n44 (88%)\n163 (85%)\n\n\nNausea\n\n\n\n\n\n\n\n\n    0\n55 (25%)\n12 (26%)\n43 (24%)\n\n\n    1\n169 (75%)\n34 (74%)\n135 (76%)\n\n\nFever\n\n\n\n\n\n\n\n\n    0\n127 (74%)\n32 (80%)\n95 (73%)\n\n\n    1\n44 (26%)\n8 (20%)\n36 (27%)\n\n\nHeadache\n\n\n\n\n\n\n\n\n    0\n83 (38%)\n11 (25%)\n72 (41%)\n\n\n    1\n137 (62%)\n33 (75%)\n104 (59%)\n\n\nJoint pain\n\n\n\n\n\n\n\n\n    0\n159 (85%)\n32 (84%)\n127 (85%)\n\n\n    1\n29 (15%)\n6 (16%)\n23 (15%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nDo you think the symptoms selected for the case definition were the right ones, or would you change anything?\n\n\n\n\n\n\n\n\n\nDo you feel like a challenge?\n\n\n\n\n\nIf you want, present the symptoms in an ordered bar chart. To do so, reshape the data using pivot_longer(), and then group_by(), summarise() and count() to tally up the counts for each symptom, stratified by case definition. Use ggplot2::coord_flip() for a better visualisation.\n\n\n\n\n\nb) Extra - Bar plot of symptoms stratified by case definition.\n\n\nShow the code\n# Create list of symptom variables:\nsymptoms &lt;- c(\"diarrhoea\", \n              \"bloody\", \n              \"vomiting\", \n              \"abdo\", \n              \"nausea\", \n              \"fever\", \n              \"headache\", \n              \"jointpain\")\n\n# Create nice labels for case definition:\ncaselabs &lt;- ggplot2::as_labeller(c(\"0\" = \"Non-case\", \n                                   \"1\" = \"Case\"))\n# Select variables and cases:\nsymptom_bar &lt;- copdata %&gt;% \n  # Select symptom columns:\n  select(case, c(all_of(symptoms))) %&gt;%\n  # Drop NAs:\n  drop_na() %&gt;% \n  # Reshape (pivot longer):\n  pivot_longer(!case, \n               names_to = \"Symptoms\", \n               values_drop_na = TRUE) %&gt;% \n  # Keep only TRUE values:\n  filter(value == \"1\") %&gt;% \n \n   # Group by symptoms and case:\n  group_by(Symptoms, case) %&gt;% \n  # Count for each symptom by case:\n  dplyr::summarise(count = n()) %&gt;% \n  # Create plot:\n  ggplot(\n    mapping = aes(\n    # Order symptom bars so most common ones are ontop:\n    x = reorder(Symptoms, desc(count), decreasing = TRUE), \n    y = count)) +\n  # Display bars as proportions\n  geom_bar(stat = \"identity\") +\n  # Update x axis label:\n  xlab(\"Symptoms\") +\n  # Update y axis label:\n  ylab(\"Proportion of respondents\") +\n  # Flip plot on its side so symptom labels are clear:\n  coord_flip() +\n  # Facet the plot by (labelled) case:\n  facet_wrap(facets = \"case\",\n             labeller = caselabs,\n             ncol = 2)\n\n\n`summarise()` has grouped output by 'Symptoms'. You can override using the\n`.groups` argument.\n\n\nShow the code\n# Print plot:\nsymptom_bar"
  },
  {
    "objectID": "Lab_and_Descriptive.html#attack-proportions",
    "href": "Lab_and_Descriptive.html#attack-proportions",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.7 Attack proportions",
    "text": "3.7 Attack proportions\n\na) Calculate the overall attack proportions (percentage of cases among the total observed individuals). You could use tabyl().\n\n\nShow the code\n# Create table of case status:\ntotal_ap &lt;- tabyl(copdata, case) %&gt;% \n # Add row totals:\n  adorn_totals(where = \"row\") %&gt;% \n  # Add percentages with 1 digit after the decimal point:\n  adorn_pct_formatting(digits = 1) %&gt;% \n  # Filter to rows where case is TRUE:\n  filter(case == \"1\") %&gt;% \n  # Select the column percent:\n  select(percent) %&gt;% \n  # Extract (pull) the value from this cell:\n  pull()\n\n# Print result:\ntotal_ap\n\n\n[1] \"57.3%\"\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat can you infer from the overall attack proportion about this outbreak and possible vehicles/exposures?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above questions, have a look here\n\n\n\n\n\nThe overall attack proportion is 57.3%. This means that more than half of the people who ate a meal were cases!\n\n\n\n\n\nb) Calculate attack proportions for group, class and sex by case status. You could use tabyl() (as you did in 3.4) or gtsummary::tbl_summary.\n\n\nShow the code\n# Table to calculate attack proportions:\nattack_prop &lt;- copdata %&gt;% \n  # Select columns:\n  select (case, class, group, sex) %&gt;% \n  \n  # Create table:\n  tbl_summary(\n    # Stratified by case\n    by = case,\n    # with row percentages\n    percent = \"row\") %&gt;%\n  \n  # Add totals:\n  add_overall() %&gt;%\n  \n  # Make variable names bold and italics:\n  bold_labels() %&gt;% \n  italicize_labels() %&gt;% \n  \n  # Modify header:\n  modify_header(\n    label = \"**Characteristic**\",\n    stat_0 = \"**Overall** **N** = {N}\",\n    stat_1 = \"**Non-case** **N** = {n}\",\n    stat_2 = \"**Case** **N** = {n}\"\n  )\n\n\n# Print table:\nattack_prop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall N = 3771\nNon-case N = 1611\nCase N = 2161\n\n\n\n\nclass\n\n\n\n\n\n\n\n\n    1\n131 (100%)\n63 (48%)\n68 (52%)\n\n\n    2\n101 (100%)\n44 (44%)\n57 (56%)\n\n\n    3\n111 (100%)\n38 (34%)\n73 (66%)\n\n\n    Unknown\n34\n16\n18\n\n\ngroup\n\n\n\n\n\n\n\n\n    teacher\n15 (100%)\n9 (60%)\n6 (40%)\n\n\n    student\n362 (100%)\n152 (42%)\n210 (58%)\n\n\nsex\n\n\n\n\n\n\n\n\n    female\n213 (100%)\n96 (45%)\n117 (55%)\n\n\n    male\n164 (100%)\n65 (40%)\n99 (60%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "Lab_and_Descriptive.html#draft-the-relevant-paragraphs-and-tables-andor-figures-in-your-outbreak-report-methods-and-results.",
    "href": "Lab_and_Descriptive.html#draft-the-relevant-paragraphs-and-tables-andor-figures-in-your-outbreak-report-methods-and-results.",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.8 Draft the relevant paragraph(s) and table(s) and/or figure(s) in your outbreak report (Methods and results).",
    "text": "3.8 Draft the relevant paragraph(s) and table(s) and/or figure(s) in your outbreak report (Methods and results).\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nTo save your tabyl table as a .docx, you could convert your tabyl to flextable (as_flex_table()), ensure only one line per row (flextable::autofit()) and save as .docx (flextable::save_as_docx(path = \"nameoftable.docx\")"
  },
  {
    "objectID": "Univariate.html",
    "href": "Univariate.html",
    "title": "Univariable analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nPerform hypothesis tests.\nEstimate risk ratios (also called relative risk) for categorical data.\nInterpret the univariable results.\n(Optional) Investigate dose-response relationships in categorical data."
  },
  {
    "objectID": "Univariate.html#learning-outcomes",
    "href": "Univariate.html#learning-outcomes",
    "title": "Univariable analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nPerform hypothesis tests.\nEstimate risk ratios (also called relative risk) for categorical data.\nInterpret the univariable results.\n(Optional) Investigate dose-response relationships in categorical data."
  },
  {
    "objectID": "Univariate.html#storyplot-description",
    "href": "Univariate.html#storyplot-description",
    "title": "Univariable analysis",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nYou have just estimated risk ratios (RR) of individual food items manually to better understand the concept. RR give you an idea of which food items could be the culprit(s) of the outbreak.\nNow, you will practice performing hypothesis testing and calculating RR in R to investigate the associations of suspicious food items with the disease.\nNote that, although this is not an exhaustive list of tests, the following can be useful for this exercise (relevant for comparisons between two groups):\n\nFor continuous variables:\n\nshapiro.test() (for checking if normally distributed)\nt.test() (for normal distributions)\nwilcox.test() (for non-parametric testing. Used to determine if two numeric samples are from the same distribution, when their populations are not normally distributed or have unequal variance.)\n\nFor categorical variables:\n\nchisq.test() (if all comparisons include at least 5 cases)\nfisher.test() (if there are &lt; 5 cases for any comparison)"
  },
  {
    "objectID": "Univariate.html#questionsassignments",
    "href": "Univariate.html#questionsassignments",
    "title": "Univariable analysis",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments"
  },
  {
    "objectID": "Univariate.html#install-packages-and-load-libraries",
    "href": "Univariate.html#install-packages-and-load-libraries",
    "title": "Univariable analysis",
    "section": "3.1. Install packages and load libraries",
    "text": "3.1. Install packages and load libraries\n\n\nShow the code\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales,\n               EpiStats,\n               broom)"
  },
  {
    "objectID": "Univariate.html#import-your-data",
    "href": "Univariate.html#import-your-data",
    "title": "Univariable analysis",
    "section": "3.2. Import your data",
    "text": "3.2. Import your data\n\n\nShow the code\n# Import the raw data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"Spetses_clean2_2024.rds\"), trust = T)"
  },
  {
    "objectID": "Univariate.html#hypothesis-tests-for-other-variables",
    "href": "Univariate.html#hypothesis-tests-for-other-variables",
    "title": "Univariable analysis",
    "section": "3.3. Hypothesis tests for other variables",
    "text": "3.3. Hypothesis tests for other variables\nCheck if the following variables are associated with being a case: age, sex, class and group.\n\na) age\nWith the Shapiro-Wilk test we check if the variables are following the normal distribution. The null hypothesis is that the data follow a normal distribution, therefore, rejecting the null hypothesis means that the data do not follow the normal distribution. A p-value below the cutoff for rejecting the null hypothesis, e.g., a p-value&lt;0.05 means that we reject the null hypothesis that the data follow the normal distribution. For age, the p-value is &lt;0.05, therefore we reject the null hypothesis that the data are normally distributed. As we see in the graph most frequently reported age is &lt;20 years.\n\n\nShow the code\n# Check if age overall follows a normal distribution:\nshapiro.test(copdata$age)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  copdata$age\nW = 0.31302, p-value &lt; 2.2e-16\n\n\nShow the code\n# Can simply have a look at\nhist(copdata$age)\n\n\n\n\n\n\n\n\n\nShow the code\n# Looking only at the students:\nstudents &lt;- copdata %&gt;% \n  filter(group == \"student\")\nhist(students$age)\n\n\n\n\n\n\n\n\n\nAge overall (nor within the students’ group) is not normally distributed.\nWe compare the age for cases and non-cases using the Wilcoxon test that is used when the data are not normally distributed. The null hypothesis is that there is no difference in the age between the two groups compared. Given that p-value&gt;0.05 we do not reject the null hypothesis.\n\n\nShow the code\n# Perform Wilcoxon rank sum test on age and sex:\nwilcox.test(age ~ case, \n            data = copdata)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age by case\nW = 15934, p-value = 0.1512\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nb) sex\n\n\nShow the code\ncopdata %&gt;% \n  select(sex, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1611\n1\nN = 2161\np-value2\n\n\n\n\nsex\n\n\n\n\n0.3\n\n\n    female\n96 (60%)\n117 (54%)\n\n\n\n\n    male\n65 (40%)\n99 (46%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do these results tell you - is there an association between sex and being a case?\nDo these results differ from what you expected when looking at the descriptive figures (case proportions stratified by sex, or the age sex pyramid)? If so, why do you think this is?\n\n\n\n\n\nc) class\n\n\nShow the code\ncopdata %&gt;% \n  select(class, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1611\n1\nN = 2161\np-value2\n\n\n\n\nclass\n\n\n\n\n0.090\n\n\n    1\n63 (43%)\n68 (34%)\n\n\n\n\n    2\n44 (30%)\n57 (29%)\n\n\n\n\n    3\n38 (26%)\n73 (37%)\n\n\n\n\n    Unknown\n16\n18\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nIn this case you have a 2x3 contingency table of class against disease status, we can use a chi-square here. P-value of the association between class and age is p-val = 0.09, suggesting that there is an association at the p-val = 0.20 level among at least one of the 3 different classes. Fellows may want to investigate this further, but in the remaining of the study this is not explored further.\nA hypothesis could be that one of the classes sat together and, for whatever reason, they ate more of the contaminated food item at those tables. This could be further studied if we had the spatial distribution of where the people sat at the dinner. Another hypothesis is that one of the classes differ from other classes in some characteristics that made them more susceptible or more exposed to the infected food item.\n\n\nd) group\n\n\nShow the code\ncopdata %&gt;% \n  select(group, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1611\n1\nN = 2161\np-value2\n\n\n\n\ngroup\n\n\n\n\n0.2\n\n\n    teacher\n9 (5.6%)\n6 (2.8%)\n\n\n\n\n    student\n152 (94%)\n210 (97%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\nP-value of the association between group and age is p-val = 0.2, suggesting that there may be an association at the p-val = 0.20 level. Explanations are like above, with variable class.\n\n\nLet’s do all together\n\n\nShow the code\ncopdata %&gt;% \n  select(sex, class, group, case) %&gt;% \n  tbl_summary(by = case) %&gt;% \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1611\n1\nN = 2161\np-value2\n\n\n\n\nsex\n\n\n\n\n0.3\n\n\n    female\n96 (60%)\n117 (54%)\n\n\n\n\n    male\n65 (40%)\n99 (46%)\n\n\n\n\nclass\n\n\n\n\n0.090\n\n\n    1\n63 (43%)\n68 (34%)\n\n\n\n\n    2\n44 (30%)\n57 (29%)\n\n\n\n\n    3\n38 (26%)\n73 (37%)\n\n\n\n\n    Unknown\n16\n18\n\n\n\n\ngroup\n\n\n\n\n0.2\n\n\n    teacher\n9 (5.6%)\n6 (2.8%)\n\n\n\n\n    student\n152 (94%)\n210 (97%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test"
  },
  {
    "objectID": "Univariate.html#risk-ratios",
    "href": "Univariate.html#risk-ratios",
    "title": "Univariable analysis",
    "section": "3.4. Risk Ratios",
    "text": "3.4. Risk Ratios\nThe risk ratios of each food item (including the 2x2 table) are reported below. The output of the CS() command is two tables: one with the 2x2 table and one with the risk difference, the risk ratio and the attributable fraction among exposed as well as the attributable fraction among the population (and the confidence intervals for all the estimates). The Chi-square and the p-value are also reported. In the second part, a table with all the food items is printed including attack rates for exposed and unexposed as well as risk ratios and the 95% confidence intervals (CI ll and CI ul, for the lower and upper interval) and p-values.\n\na) Calculate 95% CI Risk Ratios for food\nTo see if food items (note these are categorical variables) are associated with being a case, calculate risk ratios and 95% confidence intervals for food items. You can calculate this individually for each food item (using CSTable()), or all at once (see hint below).\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nCreate a food_vars vector containing food variables of interest and use the function CSTable() of the EpiStats package.\nUsing this hint, you will create a table with the name of exposure variables, the total number of exposed, the number of exposed cases, the attack rate among the exposed, the total number of unexposed, the number of unexposed cases, the attack rate among the unexposed, risk ratios, 95% percent confidence intervals, and p-values. Amazing, isn’t it? Have a look at ??CSTable to learn more.\n\n\n\n\n\nShow the code\n# You could use the EpiStats package for each food item\nCS(copdata, \"case\", \"feta\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     156       115   271 0.58\nUnexposed    60        42   102 0.59\nTotal       216       157   373 0.58\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference          -0.01    -0.12     0.10\nRisk ratio                0.98     0.81     1.19\nPrev. frac. ex.           0.02    -0.19     0.19\nPrev. frac. pop           0.02       NA       NA\nchi2(1)                   0.05       NA       NA\nPr&gt;chi2                  0.826       NA       NA\n\n\nShow the code\nCS(copdata, \"case\", \"sardines\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     150       105   255 0.59\nUnexposed    65        52   117 0.56\nTotal       215       157   372 0.58\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference           0.03    -0.08     0.14\nRisk ratio                1.06     0.87     1.28\nAttr. frac. ex.           0.06    -0.14     0.22\nAttr. frac. pop           0.04       NA       NA\nchi2(1)                   0.35       NA       NA\nPr&gt;chi2                  0.553       NA       NA\n\n\nShow the code\nCS(copdata, \"case\", \"eggplant\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     123        93   216 0.57\nUnexposed    83        60   143 0.58\nTotal       206       153   359 0.57\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference          -0.01    -0.12     0.09\nRisk ratio                0.98     0.82     1.18\nPrev. frac. ex.           0.02    -0.18     0.18\nPrev. frac. pop           0.01       NA       NA\nchi2(1)                   0.04       NA       NA\nPr&gt;chi2                  0.837       NA       NA\n\n\nShow the code\nCS(copdata, \"case\", \"pasta\")\n\n\n$df1\n          Cases Non Cases Total Risk\nExposed     202       136   338 0.60\nUnexposed    13        23    36 0.36\nTotal       215       159   374 0.57\n\n$df2\n                Point estimate 95%CI.ll 95%CI.ul\nRisk difference           0.24     0.07     0.40\nRisk ratio                1.65     1.06     2.58\nAttr. frac. ex.           0.40     0.06     0.61\nAttr. frac. pop           0.37       NA       NA\nchi2(1)                   7.45       NA       NA\nPr&gt;chi2                  0.006       NA       NA\n\n\n\n\nShow the code\n# You can save time (and probably typos!) by creating a vector for food variables...\nfood_vars &lt;- c(\"feta\", \"sardines\", \"eggplant\", \"pasta\", \n               \"veal\", \"tomsal\", \"dessert\", \"bread\",  \n               \"champagne\", \"beer\", \"redwine\", \"whitewine\")\n\n# ...and using EpiStats::CSTable() to run all variables together!\nCSTable(copdata, \"case\", food_vars)\n\n\n$df\n          Tot.Exp Cases.Exp AR.Exp% Tot.Unexp Cases.Unexp AR.Unexp%   RR CI.ll\npasta         338       202   59.76        36          13     36.11 1.65  1.06\nveal          338       201   59.47        36          14     38.89 1.53  1.01\nchampagne     316       187   59.18        48          21     43.75 1.35  0.97\ntomsal        211       114   54.03       154          95     61.69 0.88  0.73\ndessert       149        90   60.40       198         106     53.54 1.13  0.94\nbeer          281       166   59.07        78          41     52.56 1.12  0.89\nredwine        80        42   52.50       259         150     57.92 0.91  0.72\nsardines      255       150   58.82       117          65     55.56 1.06  0.87\nwhitewine     260       150   57.69        98          54     55.10 1.05  0.85\nbread         342       196   57.31        29          16     55.17 1.04  0.74\nfeta          271       156   57.56       102          60     58.82 0.98  0.81\neggplant      216       123   56.94       143          83     58.04 0.98  0.82\n          CI.ul p(Chi2)\npasta      2.58   0.006\nveal       2.32   0.018\nchampagne  1.89   0.044\ntomsal     1.04   0.144\ndessert    1.36   0.202\nbeer       1.42   0.303\nredwine    1.14   0.393\nsardines   1.28   0.553\nwhitewine  1.29   0.659\nbread      1.46   0.823\nfeta       1.19   0.826\neggplant   1.18   0.837\n\n\n\n\nb) Prepare the RR table for publication\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse flextable() and set_header_labels().\n\n\n\n\n\nShow the code\nrr_tbl &lt;- CSTable(copdata, \"case\", food_vars) %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column() %&gt;% \n  flextable() %&gt;% \n   set_header_labels(\n     values = c(\"Food Item\",\n                \"Total exposed\",     \n               \"Cases exposed\", \n               \"AR among exposed\",    \n               \"Total unexposed\",\n               \"Cases unexposed\",\n               \"AR among unexposed\",\n               \"RR\",         \n               \"95% lower CI\",             \n               \"95% upper CI\",\n               \"p-value\"))\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\n· What can you infer from this table?\n· Considering the relative risks, which food or drink items do you think were most likely to be the vehicle(s) of infection in this outbreak?\n· Do you think there are any confounders or effect modifiers? If so, how would you investigate these further?\n\n\n\nThe interesting results here are that the food items that are most suspicious are veal, pasta and champagne. Pasta as such is unlikely to be contaminated, but as you can see in the picture (and from the dinner night), it was served with pesto! Maybe it was the pesto? Who-ho-ho!\nBefore one jumps into conclusions, consider that this result could be due to confounding! Maybe pasta was “clean” but eaten by all the people who ate the food item that actually was contaminated!(Optional)"
  },
  {
    "objectID": "Univariate.html#optional-dose-response",
    "href": "Univariate.html#optional-dose-response",
    "title": "Univariable analysis",
    "section": "3.5. (Optional) Dose Response",
    "text": "3.5. (Optional) Dose Response\nCheck for a dose-response relationship between the food items with the highest RR values (the top 3) and being a case.\n\na) Veal\nUsing epitools::riskratio function:\n\n\nShow the code\nepitools::riskratio(copdata$vealD,\n                    copdata$case,\n                    conf.level = 0.95)\n\n\n$data\n         Outcome\nPredictor   0   1 Total\n    0      19  15    34\n    1      30  40    70\n    2      78 106   184\n    3      33  54    87\n    Total 160 215   375\n\n$measure\n         risk ratio with 95% C.I.\nPredictor estimate     lower    upper\n        0 1.000000        NA       NA\n        1 1.295238 0.8431805 1.989659\n        2 1.305797 0.8769752 1.944304\n        3 1.406897 0.9314233 2.125090\n\n$p.value\n         two-sided\nPredictor midp.exact fisher.exact chi.square\n        0         NA           NA         NA\n        1 0.22186384    0.2951163 0.21193013\n        2 0.15357032    0.1884220 0.14587265\n        3 0.07956697    0.1017336 0.07298506\n\n$correction\n[1] FALSE\n\nattr(,\"method\")\n[1] \"Unconditional MLE & normal approximation (Wald) CI\"\n\n\nUsing a binomial regression:\n\n\nShow the code\n# Binomial regression for RRs. \n# The outcome needs to be exponentiated so we can interpret it properly!\nbinom_vealD &lt;- glm(case ~ vealD, data = copdata, \n             family = binomial(link = \"log\"))\n\n# To get exponentiated:\nbinom_vealD_exp &lt;- glm(case ~ vealD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_vealD_exp\n\n\n\n  \n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do these results tell you?\n\n\n\nResults suggest a dose response relationship of having eaten veal, pointing towards veal as the potential vehicle. The higher the amount of veal they ate, the stronger is the association (RR) with getting ill/being a case.\n\n\nb) Pasta\nUsing epitools::riskratio function:\n\n\nShow the code\nepitools::riskratio(copdata$pastaD,                     \n                    copdata$case,                     \n                    conf.level = 0.95)\n\n\n$data\n         Outcome\nPredictor   0   1 Total\n    0      23  13    36\n    1      32  38    70\n    2      76 107   183\n    3      28  57    85\n    Total 159 215   374\n\n$measure\n         risk ratio with 95% C.I.\nPredictor estimate     lower    upper\n        0 1.000000        NA       NA\n        1 1.503297 0.9257878 2.441057\n        2 1.619168 1.0310538 2.542742\n        3 1.857014 1.1730804 2.939696\n\n$p.value\n         two-sided\nPredictor  midp.exact fisher.exact chi.square\n        0          NA           NA         NA\n        1 0.081364161  0.100893180 0.07613202\n        2 0.015337953  0.017069765 0.01373981\n        3 0.002010616  0.002370887 0.00162311\n\n$correction\n[1] FALSE\n\nattr(,\"method\")\n[1] \"Unconditional MLE & normal approximation (Wald) CI\"\n\n\nUsing a binomial regression:\n\n\nShow the code\n# Let's get the results directly exponentiated\nbinom_pastaD_exp &lt;- glm(case ~ pastaD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_pastaD_exp\n\n\n\n  \n\n\n\n\n\nc) Champagne\nUsing epitools::riskratio function:\n\n\nShow the code\nepitools::riskratio(copdata$champagneD,                     \n                    copdata$case,                     \n                    conf.level = 0.95)\n\n\n$data\n         Outcome\nPredictor   0   1 Total\n    0      27  21    48\n    1      93 111   204\n    2      12  32    44\n    3      24  44    68\n    Total 156 208   364\n\n$measure\n         risk ratio with 95% C.I.\nPredictor estimate     lower    upper\n        0 1.000000        NA       NA\n        1 1.243697 0.8812613 1.755193\n        2 1.662338 1.1502014 2.402507\n        3 1.478992 1.0260296 2.131923\n\n$p.value\n         two-sided\nPredictor  midp.exact fisher.exact  chi.square\n        0          NA           NA          NA\n        1 0.188922591  0.201367850 0.183280359\n        2 0.005584928  0.006247816 0.004961941\n        3 0.027627736  0.036334120 0.025117641\n\n$correction\n[1] FALSE\n\nattr(,\"method\")\n[1] \"Unconditional MLE & normal approximation (Wald) CI\"\n\n\nUsing a binomial regression:\n\n\nShow the code\n# Let's get the results directly exponentiated\nbinom_champagneD_exp &lt;- glm(case ~ champagneD, data = copdata, \n                       family = binomial(link = \"log\")) %&gt;% \n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)\n\nbinom_champagneD_exp"
  },
  {
    "objectID": "Univariate.html#summary",
    "href": "Univariate.html#summary",
    "title": "Univariable analysis",
    "section": "3.6 Summary",
    "text": "3.6 Summary\nAs a summary of what you’ve done above, answer these questions:\n\nIs the respondents’ sex associated with being a case?\nIs the school class associated with being a case?\nWhich foods increase the risk of being a case?\n(Optional) Is there a dose-response relationship between the food items and being a case?\nWhat do you think is the most likely culprit(s) of this outbreak at this point? Are there any risk factors you would like to highlight?"
  },
  {
    "objectID": "Stratified.html",
    "href": "Stratified.html",
    "title": "Stratified analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nConsider the effect of confounding and effect modification on the association between exposure and disease,\nPerform stratified analysis using the Mantel-Haenszel approach\n\nThe use of stratified analysis, is the first step to identify confounding factors and effect modifiers one by one (after, of course, thinking which variables could potentially be confounders or effect modifiers). As the final step, you will be using Regression Models to account for confounding and check for effect modification. We will see these with you in the Multivariable Module (MVA), next year."
  },
  {
    "objectID": "Stratified.html#learning-outcomes",
    "href": "Stratified.html#learning-outcomes",
    "title": "Stratified analysis",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nConsider the effect of confounding and effect modification on the association between exposure and disease,\nPerform stratified analysis using the Mantel-Haenszel approach\n\nThe use of stratified analysis, is the first step to identify confounding factors and effect modifiers one by one (after, of course, thinking which variables could potentially be confounders or effect modifiers). As the final step, you will be using Regression Models to account for confounding and check for effect modification. We will see these with you in the Multivariable Module (MVA), next year."
  },
  {
    "objectID": "Stratified.html#storyplot-description",
    "href": "Stratified.html#storyplot-description",
    "title": "Stratified analysis",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nFrom the univariable analysis, it seems that eating orzpo and eating pasta as well as drinking champagne are associated with the highest risk of becoming ill. There are, however, many other food items that are associated with an increased risk (even if not statistically significant).\nYou should next think about potential confounders and about effect modification. Think about which variables you might want to check for effect modification or confounding. One common strategy is to base this decision on the results obtained in the univariable analysis and a p-value threshold of 0.20-0.25. Also, food items that are known risk factors for gastroenteritis could also be included regardless of their univariable p-value."
  },
  {
    "objectID": "Stratified.html#questionsassignments",
    "href": "Stratified.html#questionsassignments",
    "title": "Stratified analysis",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments"
  },
  {
    "objectID": "Stratified.html#confounders-and-effect-modification",
    "href": "Stratified.html#confounders-and-effect-modification",
    "title": "Stratified analysis",
    "section": "3.1. Confounders and effect modification",
    "text": "3.1. Confounders and effect modification\nDiscuss how to identify potential confounders and effect modification. Draw dummy tables before coding to have clear what you want to achieve."
  },
  {
    "objectID": "Stratified.html#install-packages-and-load-libraries",
    "href": "Stratified.html#install-packages-and-load-libraries",
    "title": "Stratified analysis",
    "section": "3.2. Install packages and load libraries",
    "text": "3.2. Install packages and load libraries\n\n\nShow the code\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales,\n               EpiStats)"
  },
  {
    "objectID": "Stratified.html#import-your-data",
    "href": "Stratified.html#import-your-data",
    "title": "Stratified analysis",
    "section": "3.3. Import your data",
    "text": "3.3. Import your data\n\n\nShow the code\n# Import the raw data set: \ncopdata &lt;- rio::import(here::here(\"data\", \"Spetses_clean2_2024.rds\"))\n\n\nWarning: Missing `trust` will be set to FALSE by default for RDS in 2.0.0."
  },
  {
    "objectID": "Stratified.html#consider-and-assess-for-confounding-andor-effect-modification",
    "href": "Stratified.html#consider-and-assess-for-confounding-andor-effect-modification",
    "title": "Stratified analysis",
    "section": "3.4. Consider and assess for confounding and/or effect modification",
    "text": "3.4. Consider and assess for confounding and/or effect modification\nHave a look at the relative risk for being a case having eaten a specific food item (for example, moussake), when stratified by another variable (for example, veal). You may consider stratifying by veal, as it has the highest RR in the univariable analysis.\nThere are many variables in this dataset and it might not make sense to stratify each variable by each other variable on our search for effect modifiers and confounders.\nHowever, we also don’t want to be too restrictive as a variable which actually (i.e. causally) is associated with the outcome might not show a significant association at the significant level we decided (say 5%) in the univariable analysis due to confounding. Therefore, we could test all variables statistically significant at the 15%, 20%, or 25% level (specific percentage to be decided by your group). In our solutions here, we are looking at pasta and champagne, stratified by veal, but you may decide to look at other food items as well.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nUse the function csinter() of the EpiStats package.\n\n\n\n\na) Pasta as exposure of interest, stratified by having eaten veal\nIf we stratify the effect of pasta by veal we ask the question: does eating veal modify or confound the association between eating pasta and being a case?\n\n\nShow the code\nstratall &lt;- copdata %&gt;% \n  # Mutate across to convert cases to numeric:\n  mutate(across(.cols = case, \n                .fns = ~ as.numeric(.)))\n\n# Pass data to the csinter function:\nvealstrata &lt;- csinter(x = stratall, \n                       cases = \"case\", \n                       exposure = \"pasta\", \n                       by = \"veal\")\n\nvealstrata\n\n\n$df1\n  CSInter case - pasta by(veal) Total Cases Risk %          P.est. Stats\n1                      veal = 1   338  &lt;NA&gt;     NA Risk difference  0.10\n2                       Exposed   330   198  60.00      Risk Ratio  1.20\n3                     Unexposed     8     4  50.00 Attrib.risk.exp  0.17\n4                                  NA  &lt;NA&gt;     NA Attrib.risk.pop  0.16\n5                      veal = 0    36  &lt;NA&gt;     NA Risk difference  0.02\n6                       Exposed     8     3  37.50      Risk Ratio  1.05\n7                     Unexposed    28    10  35.71 Attrib.risk.exp  0.05\n8                                  NA  &lt;NA&gt;     NA Attrib.risk.pop  0.01\n9           Missing / Missing %     3  0.8%     NA            &lt;NA&gt;    NA\n  95%CI.ll 95%CI.ul\n1    -0.25     0.45\n2     0.60     2.41\n3    -0.68     0.59\n4       NA       NA\n5    -0.36     0.40\n6     0.38     2.92\n7    -1.65     0.66\n8       NA       NA\n9       NA       NA\n\n$df2\n                  Point Estimate Chi2 p.value  Stats 95%CI.ll 95%CI.ul\n1      Woolf test of homogeneity 0.04   0.833     NA       NA       NA\n2             Crude RR for pasta   NA      NA   1.53     1.01     2.32\n3  MH RR pasta adjusted for veal   NA      NA   1.15     0.64     2.04\n4 Adjusted/crude relative change   NA      NA -25.08       NA       NA\n\n\nLet’s check if veal is associated with pasta (if we are thinking pasta may be a confounder, we need to see if there is an association between the potential confounder (pasta) and the exposure (veal)):\n\n\nShow the code\n# Perform Wilcoxon rank sum test on veal and pasta:\nwilcox.test(veal ~ pasta, \n            data = copdata)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  veal by pasta\nW = 1496, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nb) Champagne as exposure of interest, stratified by having eaten veal\n\n\nShow the code\n# Pass data to the csinter function:\nchampstrata &lt;- csinter(x = stratall, \n                       cases = \"case\", \n                       exposure = \"champagne\", \n                       by = \"veal\")\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nAre there any indications to make you think there may be effect modification and/or confounding?\n\n\n\nWe could stratify by veal (the strongest risk factor in the univariable analysis), to examine if veal confounds the association between eating pasta and being a case. Before stratification, we will need to check if veal meets the conditions of being a confounder. For a variable to be a confounder it needs to be associated both with the outcome (being a case) and with the exposure (and not be in the causal pathway between exposure and outcome). We know from univariable analysis that veal is associated with being a case. If we run a Wilcoxon rank sum test, we will see that veal is also associated with pasta (indeed, you can see that most people either had both pasta and veal or neither of these food items, so they are associated with each other).\nAbove, we uses ccinter to stratify and save the object as “vealstrata”.\nvealstrata: Within the stratum of the people who ate veal, pasta has no significant effect (RR = 1.20, CI: 0.60 - 2.41). The same holds within the stratum of people who didn’t eat veal (RR = 1.05, CI = 0.38, 2.92). The adjusted MH-RR also suggests that pasta has no effect (RRadj = 1.15, CI: 0.80 - 2.85).  To identify confounding, we want to look at the % change between the crude and the adjusted RR. This is given by the csinter output “Adjusted/crude relative change”.  The difference between the crude and the MH-RR in this case is &gt;20% suggesting that veal confounds the association between pasta and the disease.\nThis result suggest that pasta is not a risk factor of the disease and that the crude observed effect was due to the confounding effect of veal.\nIf you stratify by pasta, you see that pasta does not confound the association between veal and the disease. The same applies if you stratify the exposure to veal by other variables. The above, the higher RR for veal and the dose response relationship we found earlier for veal (remember this was optional) provide additional evidence that there was something going on with the veal with pesto dish!"
  },
  {
    "objectID": "Case_definition.html",
    "href": "Case_definition.html",
    "title": "Case Definition",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nApply case definition criteria to a dataset using logical arguments in R"
  },
  {
    "objectID": "Case_definition.html#learning-outcomes",
    "href": "Case_definition.html#learning-outcomes",
    "title": "Case Definition",
    "section": "",
    "text": "At the end of the session, participants will be able to:\n\nApply case definition criteria to a dataset using logical arguments in R"
  },
  {
    "objectID": "Case_definition.html#storyplot-description",
    "href": "Case_definition.html#storyplot-description",
    "title": "Case Definition",
    "section": "2. Story/plot description",
    "text": "2. Story/plot description\nYou will now create a new column in the data set to hold the case definition you decided in a previous step during your investigation. You can call this column case and set it to 1 if the individual meets the case definition criteria and 0 if not. You will use this column later on for any calculations needed (descriptive statistics, two-by-two tables to compute measures of association, etc.) to figure out the culprit of this outbreak."
  },
  {
    "objectID": "Case_definition.html#questionsassignments",
    "href": "Case_definition.html#questionsassignments",
    "title": "Case Definition",
    "section": "3. Questions/Assignments",
    "text": "3. Questions/Assignments\nIf you closed your R project, please open it again and load the clean dataset. We strongly recommend you use the Spetses_clean1_2024.rds. This is just to be sure all needed changes in that file for the code to work have been done (as you may have changed the file in a slightly different way than we have).\nTo be sure we all start from the same case definition, let’s agree that a case was defined as a person who:\n\nattended the school dinner on 11 November 2006 (i.e. is on the linelist)\nate a meal at the school dinner (i.e. was exposed)\nfell ill after the start of the meal\nfell ill within the time period of interest after the school dinner\nsuffered from diarrhoea with or without blood, or vomiting\n\nNon cases (not-ill) were defined as people who:\n\nattended the school dinner on 11 November 2006 (i.e. are on the linelist)\nate a meal at the school dinner (i.e. were exposed)\ndid not fall ill within the time period of interest\ndid not develop diarrhoea (with or without blood) or vomiting"
  },
  {
    "objectID": "Case_definition.html#install-packages-if-needed-and-load-libraries",
    "href": "Case_definition.html#install-packages-if-needed-and-load-libraries",
    "title": "Case Definition",
    "section": "3.1 Install packages (if needed) and load libraries",
    "text": "3.1 Install packages (if needed) and load libraries\n\n\nShow the code\n# Load the required libraries into the current R session:\npacman::p_load(rio, \n               here, \n               tidyverse, \n               skimr,\n               plyr,\n               janitor,\n               lubridate,\n               gtsummary, \n               flextable,\n               officer,\n               epikit, \n               apyramid, \n               scales)"
  },
  {
    "objectID": "Case_definition.html#import-your-data",
    "href": "Case_definition.html#import-your-data",
    "title": "Case Definition",
    "section": "3.2 Import your data",
    "text": "3.2 Import your data\n\n\nShow the code\n# Import the clean data set:\ncopdata &lt;- rio::import(here::here(\"data\", \"Spetses_clean1_2024.rds\"), trust = TRUE)"
  },
  {
    "objectID": "Case_definition.html#identify-the-variables-you-need-to-apply-the-case-definition-criteria.",
    "href": "Case_definition.html#identify-the-variables-you-need-to-apply-the-case-definition-criteria.",
    "title": "Case Definition",
    "section": "3.3 Identify the variables you need to apply the case definition criteria.",
    "text": "3.3 Identify the variables you need to apply the case definition criteria.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nThe variables we need from the dataset to apply the above case definition are: meal, ill, onset_datetime, diarrhoea, bloody and vomiting."
  },
  {
    "objectID": "Case_definition.html#create-a-new-case-column-to-hold-the-binary-case-definition-variable.-lets-think-about-how-to-do-this-little-by-little",
    "href": "Case_definition.html#create-a-new-case-column-to-hold-the-binary-case-definition-variable.-lets-think-about-how-to-do-this-little-by-little",
    "title": "Case Definition",
    "section": "3.4 Create a new case column to hold the binary case definition variable. Let’s think about how to do this little by little:",
    "text": "3.4 Create a new case column to hold the binary case definition variable. Let’s think about how to do this little by little:\n\na) Ate a meal at the school dinner\nYou decide to exclude any people from the cohort who didn’t eat at the dinner, because we specifically hypothesised a food item to be the vehicle of infection in this outbreak. Thus, filter your dataset to those who ate a meal: Keep in your dataset only those who ate a meal.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nfilter by those with meal == 1.\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat are some of the implications this decision may lead to? (excluding any people from the cohort who didn’t eat at the dinner)\n\n\n\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  filter(meal == 1)\n\n\n\n\n\n\n\n\nOnce you’ve thought about the above, have a look here\n\n\n\n\n\nSeven of the respondents actually said they did not eat the meal, but when it came to the questions about which food items they ate, they provided answers! This issue could have been minimised by:\n- At the survey state, one could adjust the design of an electronic questionnaire to prevent key questions from being skipped. This can come with both pros and cons. Allow fellows to discuss if time allows.\n- Explore your data further, realise this is the case, and recode the meal variable for these individuals as 1. =&gt; This would be the way to go, but is not what we did in our example because we tried to keep it simple, and also because it is good to show that you may not always clean the data perfectly, and that has consequences: You can highlight the importance or really explore your data in depth.\nBy making the above decision, we may be missing cases and non-cases people, and thus, modifying the final estimate of our measure of association. =&gt; It is very important to know your data, explore it deeply and try to clean it as well as possible. Every step one makes when cleaning the data may have a consequence, and we should be aware of it when making the data cleaning decisions and when interpreting the results.\n\n\n\n\n\nb) Fell ill after the start of the meal\nWe define “fell ill” as any person having had diarrhoea with OR without blood, OR vomiting. To capture this information easily, you will create a new gastrosymptoms variable. This variable will indicate that the person had one OR (“or” is R is achieved by using |) more of the clinical symptoms in your definition.\nNote that we the concept of having eaten a meal is already included as per one of the steps above.\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nCreate a new gastrosymptoms column in your line list with mutate() and case_when().\n\n\n\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat are some of the implications this decision may lead to? (defining “fell ill” as any person who reported having diarrhoea with OR without blood, OR vomiting)\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above, have a look here\n\n\n\n\n\nHaving one clinical symptom enough to be considered a potential case at this point may be considered too unspecific (low specificity). For example, a person who ate at the dinner party and developed diarrhoea for other reasons other than food poisoning (say, they recently started on antibiotics known for unbalancing the intestinal flora and causing diarrhoea) could be misclassified as a potential case. (Note we talk about potential case, and not case; that is because here we are not talking about cases per-se yet, but this decision has implications for when applying the case definition below).\nMoreover, those who did not report clinical symptoms will be defined as non-cases. Thus, we are assuming that these individuals did not develop symptoms because they didn’t report them. The missing values could be due to, for example, them skipping the questions in the questionnaire. Some individuals may be reluctant to report symptoms, due to shame, fear of repercussion, or others. It is important to think ahead, before the interview, about ways to minimise these situations. For example, through questionnaire design, you may impede skipping questions; you could promote trust by using the right interviewers (in some cases this will be someone from the community, in others someone form specific NGOs, someone of a specific race or gender, etc); choose to carry out online questionnaires vs in person (or vice versa, depending on the situation), etc.\n\n\n\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  mutate(gastrosymptoms = case_when(\n    # Those had diarrhoea...\n    diarrhoea == \"1\" |\n      #or bloody diarrhoea...\n    bloody == \"1\" |\n      # or vomiting, are marked as 1 (fell ill after the meal)\n    vomiting == \"1\" ~ 1,\n    # The rest are 0 This includes those who ate a meal but had no symptoms (did not fell ill after the meal)\n    .default = 0)\n    )\n\n\n\n\nc) Fell ill within the time period of interest\n\nHmmm… what is the time period of interest? You could start calculating the incubation period, which can be defined by calculating the time between exposure (the meal) and onset of symptoms, and then looking at the distribution of these time differences. In this outbreak, incubation periods are easy to calculate, because everyone was exposed at (roughly) the same time and on the same day (eating the meal at the school dinner party).\nDinner was served at 18:00 roughly for everyone. Create a new meal_datetime variable with this information for all people in your dataset (as per 05 Oct 2024, at 18:00h).\n\n\n\nShow the code\n# Start with copdata:\ncopdata &lt;- copdata %&gt;% \n  # Create new column for meal date and time:\n  mutate(meal_datetime = lubridate::ymd_hm(\"2024-10-05 18:00\"))\n\n\n\nYou can calculate the incubation period for each participant by subtracting onset_datetime - meal_datetime.\nThen, take the median() of that column to calculate a median incubation period, this will help you start having some hypothesis about the type of pathogen we are dealing with until the lab results come back.\n\n\n\n\n\n\n\nNeed a little bit of help?\n\n\n\n\n\nBe aware of the type of variable incubation is (check class()), as well as of missing valuesNA.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe incubation period of a disease is the time from an exposure resulting in infection until the onset of disease. Because infection usually occurs immediately after exposure, the incubation period is generally the duration of the period from the onset of infection to the onset of disease – Rothman, Greenland, Lash (2017): Modern Epidemiology, 3rd edition\n\n\n\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  mutate(incubation = onset_datetime - meal_datetime,\n         incubation = as.numeric (incubation))\n\n\nmedian(as.numeric(copdata$incubation), na.rm = TRUE)\n\n\n[1] 15\n\n\n\n\n\n\n\n\nNow we are messing up with your brain…\n\n\n\n\n\nIf you pay attention, there were two individuals who don’t have a time recorded, only a date, the day of the dinner. These people probably got sick the same night they had the dinner, but the exact time was not recoded. They way we’ve managed the data will insert “00:00” in a missing value of a time. This means that the 2 people that got sick the day of the dinner have been recorded sick before the dinner (in the early morning of the day of the dinner). The two people have a negative incubation period! This should not happen. If you feel the force is with you, you can modify this and fix the error (if you do this, your results will be a bit different than your colleagues, but similar). We will continue with this “erroneous” data, for easiness. But note that in real life, as soon as you realise there is a coding error like this, you would have to go back to your cleaning code and fix the error! This may happen a couple of times during your outbreak investigation, and is totally normal. Cleaning data is not an easy job!\n\n\n\nWe see that the median incubation time is 15 hours. This is useful information, as incubation periods tend to be relatively pathogen-specific.\nBased on this, say you define and limit the maximum incubation period to 48 hours after the meal, as the data points to a fast-acting bacterial toxin or a virus. That is, dinner participants should have developed (onset_datetime) at least one symptom (diarrhoea, bloody or vomiting) 48h after meal_datetime to become a case.\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat are some of the implications this decision may lead to? (implications of this case definition)\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above, have a look here\n\n\n\n\n\nAll those not developing at least one symptom (diarrhoea with OR without blood, OR vomiting) 48h after the dinner are considered non-cases. This could (depending on how you decide to analyse your data) include those who had no symptoms at all, those who have missing data on the onset_datetime variable, and/or those who had symptoms before eating the meal. This is a reminder that you need to be both careful and aware of the implications of your data analysis decisions. If a person had clinical symptoms before eating the meal, they are considered as not-cases. However, it could be that a person had symptoms before the meal, and yet, still got infected by the pathogen when eating their meal (bad luck, we know…). According to this definition, we would be missing that case.\n\n\n\n\n\nd) Finally, with this information you can create a new case column to hold the binary (1/0) case definition variable.\n\n\nShow the code\ncopdata &lt;- copdata %&gt;% \n  mutate(case = case_when(\n    # Those who had symptoms &lt;48h from the meal are cases (1)\n    gastrosymptoms == 1 & \n      onset_datetime &gt;= meal_datetime &\n      onset_datetime &lt;= (meal_datetime + days(2)) ~ 1,\n    # Those who had symptoms &gt;48h from the meal are non-cases (FALSE)\n    gastrosymptoms == 1 & \n      onset_datetime &gt; (meal_datetime + days(2)) ~ 0,\n    # The rest are considered non-cases. Including, those who had no symptoms at all, who have missing data on the onset_datetime variable, or who had symptoms before eating the meal \n    .default = 0)\n  )\n\n\nNote that we may be incurring in misclassification bias with the code above. The last section indicates that if a person had clinical symptoms before eating the meal, they are considered as non-cases. However, it could be that a person had symptoms before the meal, and yet, still got infected by the pathogen when eating their meal (bad luck, we know…).\nMoreover, if you remember, there were a couple of people with an dayonset, but no starthour. The code we used (lubridate::ymd_h with argument truncated = 2) results in dates with missing starthour being converted to date-time, with the missing time being set to 00:00 (midnight). This means that these two people don’t fulfill the case definition criteria because we marked their symptoms started early in the morning of Nov 11 (at 00:00), before the meal time (18:00), and thus, they did not “fell ill within the time period of interest”.\nThe two situations above are a reminder that you need to be both careful and aware of the implications of your data analysis decisions.\n\n\n\n\n\n\nLet’s stop and… think!\n\n\n\n\n\nWhat do you think are the risks of mis-classifying cases as non-cases in your analysis?\n\n\n\n\n\n\n\n\n\nIf you’ve thought about the above, have a look here\n\n\n\n\n\nWe will have bias either towards or away from the null, depending on the proportions of subjects misclassified.\n\n\n\n\n\nShow the code\n# Tabulate cases:\njanitor::tabyl(dat = copdata, case)\n\n\n\n  \n\n\n\nLet’s have a look at how many people ate a meal, had symptoms, and were considered as cases after applying our case definition:\n\n\nShow the code\ncopdata %&gt;% \n  summarise(atemeal = sum(meal == 1),\n            hadsympt = sum(gastrosymptoms == 1),\n            nb_cases = sum(case == 1)\n            )"
  },
  {
    "objectID": "Lab_and_Descriptive.html#merge-and-explore-the-lab-data.-explore-it-as-you-wish",
    "href": "Lab_and_Descriptive.html#merge-and-explore-the-lab-data.-explore-it-as-you-wish",
    "title": "Laboratory data and descriptive analysis",
    "section": "3.3 Merge and explore the lab data. Explore it as you wish!",
    "text": "3.3 Merge and explore the lab data. Explore it as you wish!\n\n\nShow the code\ncopdatalab &lt;- left_join(copdata, lab, \n                        by = \"id\")\n# Tabulate:\njanitor::tabyl(dat = copdatalab, \"RT-PCR_ecoli_etec\")"
  }
]